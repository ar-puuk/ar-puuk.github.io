{
  "hash": "8fb87539dcf50b788387a7e2710b6f67",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Overture Maps Data Download\"\nsubtitle: \"Applying DuckDB in R and Python\"\nauthor:\n  - name: Pukar Bhandari\n    email: pukar.bhandari@outlook.com\ndate: \"2024-05-22\"\ncategories: [R, Python, GIS, Data Science]\ndraft: false\nexecute:\n  eval: false\n---\n\n\n\n# Downloading Overture Maps Data with R and Python\n\nOverture Maps Foundation provides a collaborative, open-source initiative to create the world's most comprehensive and interoperable geospatial dataset. As transportation planners and data analysts, we often need access to high-quality geospatial data for buildings, transportation networks, places, and administrative boundaries. This post demonstrates how to efficiently download Overture Maps data using both R and Python with DuckDB's powerful spatial capabilities.\n\n## What is Overture Maps?\n\nOverture Maps is an open-source mapping initiative that provides global-scale geospatial data across four main themes:\n\n- **Buildings**: Footprints and building parts\n- **Transportation**: Road segments and connectors  \n- **Places**: Points of interest and place data\n- **Admins**: Administrative boundaries and localities\n- **Base**: Infrastructure, land use, land cover, and water features\n\nThe data is stored in cloud-optimized Parquet format on AWS S3, making it ideal for efficient querying and analysis.\n\n## Prerequisites\n\nBefore diving into the code, ensure you have the following dependencies installed:\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install required packages\ninstall.packages(c(\"tidyverse\", \"sf\", \"tmap\", \"DBI\", \"duckdb\", \"arrow\"))\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Install required packages\npip install duckdb matplotlib geopandas pandas shapely folium pathlib\n```\n:::\n\n\n:::\n\n## Setting Up the Environment\n\nFirst, we need to load our libraries and configure the environment for spatial data processing.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(arrow)\n\n# Set global options\noptions(scipen = 999) # avoiding scientific notation\ntmap_mode(mode = \"view\")\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport duckdb\nimport geopandas as gpd\nimport pandas as pd\nimport shapely.wkb\nimport matplotlib.pyplot as plt\nimport folium\nfrom pathlib import Path\n```\n:::\n\n\n:::\n\n## Data Type Mapping\n\nOverture data is organized by themes, and we need to map specific data types to their corresponding themes for proper S3 path construction.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the theme map\nmap_themes <- list(\n  \"locality\" = \"admins\",\n  \"locality_area\" = \"admins\",\n  \"administrative_boundary\" = \"admins\",\n  \"building\" = \"buildings\",\n  \"building_part\" = \"buildings\",\n  \"place\" = \"places\",\n  \"segment\" = \"transportation\",\n  \"connector\" = \"transportation\",\n  \"infrastructure\" = \"base\",\n  \"land\" = \"base\",\n  \"land_use\" = \"base\",\n  \"water\" = \"base\"\n)\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Define theme mapping\nTHEME_MAP = {\n    \"locality\": \"admins\",\n    \"locality_area\": \"admins\",\n    \"administrative_boundary\": \"admins\",\n    \"building\": \"buildings\",\n    \"building_part\": \"buildings\",\n    \"place\": \"places\",\n    \"segment\": \"transportation\",\n    \"connector\": \"transportation\",\n    \"infrastructure\": \"base\",\n    \"land\": \"base\",\n    \"land_use\": \"base\",\n    \"water\": \"base\",\n}\n```\n:::\n\n\n:::\n\n## Core Download Function\n\nThis function handles the DuckDB connection, S3 configuration, and spatial filtering to download only the data within your specified bounding box.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\noverture_data <- function(bbox, overture_type, dst_parquet) {\n  \n  # Validate overture_type\n  if (!overture_type %in% names(map_themes)) {\n    stop(paste(\"Valid Overture types are:\", paste(names(map_themes), collapse = \", \")))\n  }\n  \n  # Configure S3 path\n  s3_region <- \"us-west-2\"\n  base_url <- sprintf(\"s3://overturemaps-%s/release\", s3_region)\n  version <- \"2024-04-16-beta.0\"\n  theme <- map_themes[[overture_type]]\n  remote_path <- sprintf(\"%s/%s/theme=%s/type=%s/*\", base_url, version, theme, overture_type)\n  \n  # Connect to DuckDB and install extensions\n  conn <- dbConnect(duckdb::duckdb())\n  dbExecute(conn, \"INSTALL httpfs;\")\n  dbExecute(conn, \"INSTALL spatial;\")\n  dbExecute(conn, \"LOAD httpfs;\")\n  dbExecute(conn, \"LOAD spatial;\")\n  dbExecute(conn, sprintf(\"SET s3_region='%s';\", s3_region))\n  \n  # Create view and execute spatial query\n  read_parquet <- sprintf(\"read_parquet('%s', filename=TRUE, hive_partitioning=1);\", remote_path)\n  dbExecute(conn, sprintf(\"CREATE OR REPLACE VIEW data_view AS SELECT * FROM %s\", read_parquet))\n  \n  query <- sprintf(\"\n    SELECT data.*\n    FROM data_view AS data  \n    WHERE data.bbox.xmin <= %f AND data.bbox.xmax >= %f\n    AND data.bbox.ymin <= %f AND data.bbox.ymax >= %f\n  \", bbox[3], bbox[1], bbox[4], bbox[2])\n  \n  # Save results to Parquet file\n  file <- normalizePath(dst_parquet, mustWork = FALSE)\n  dbExecute(conn, sprintf(\"COPY (%s) TO '%s' WITH (FORMAT 'parquet');\", query, file))\n  dbDisconnect(conn, shutdown = TRUE)\n}\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef overture_data(bbox, overture_type, dst_parquet):\n    \"\"\"Query a subset of Overture's data and save it as a GeoParquet file.\n    \n    Parameters\n    ----------\n    bbox : tuple\n        A tuple of floats representing the bounding box (xmin, ymin, xmax, ymax) \n        in EPSG:4326 coordinate reference system.\n    overture_type : str\n        The type of Overture data to query\n    dst_parquet : str or Path\n        The path to the output GeoParquet file.\n    \"\"\"\n    if overture_type not in THEME_MAP:\n        raise ValueError(f\"Valid Overture types are: {list(THEME_MAP)}\")\n    \n    # Configure S3 connection\n    s3_region = \"us-west-2\"\n    base_url = f\"s3://overturemaps-{s3_region}/release\"\n    version = \"2024-04-16-beta.0\"\n    theme = THEME_MAP[overture_type]\n    remote_path = f\"{base_url}/{version}/theme={theme}/type={overture_type}/*\"\n    \n    # Setup DuckDB with spatial extensions\n    conn = duckdb.connect()\n    conn.execute(\"INSTALL httpfs;\")\n    conn.execute(\"INSTALL spatial;\")\n    conn.execute(\"LOAD httpfs;\")\n    conn.execute(\"LOAD spatial;\")\n    conn.execute(f\"SET s3_region='{s3_region}';\")\n    \n    # Execute spatial query\n    read_parquet = f\"read_parquet('{remote_path}', filename=true, hive_partitioning=1);\"\n    conn.execute(f\"CREATE OR REPLACE VIEW data_view AS SELECT * FROM {read_parquet}\")\n    \n    query = f\"\"\"\n    SELECT data.*\n    FROM data_view AS data\n    WHERE data.bbox.xmin <= {bbox[2]} AND data.bbox.xmax >= {bbox[0]}\n    AND data.bbox.ymin <= {bbox[3]} AND data.bbox.ymax >= {bbox[1]}\n    \"\"\"\n    \n    file = str(Path(dst_parquet).resolve())\n    conn.execute(f\"COPY ({query}) TO '{file}' WITH (FORMAT PARQUET);\")\n    conn.close()\n```\n:::\n\n\n:::\n\n## Defining Your Study Area\n\nFor spatial analysis, you need to define a bounding box for your area of interest. This can come from existing boundary data or manual coordinates.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read existing boundary data (example: Albany, NY)\nalbany_boundary <- read_sf(file.path(wd, project), layer = \"City_of_Albany\") |>\n  st_transform(4326)\n\n# Extract bounding box coordinates (xmin, ymin, xmax, ymax)\nalbany_bbox <- albany_boundary |>\n  st_bbox() |>\n  as.vector()\n\nprint(albany_bbox)\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Define study area bounding box manually\n# Manhattan example (xmin, ymin, xmax, ymax) in EPSG:4326\nbbox_example = (-74.02169, 40.696423, -73.891338, 40.831263)\n\n# Alternative: extract from existing boundary data\n# boundary_gdf = gpd.read_file(\"your_boundary.shp\")\n# bbox_example = boundary_gdf.total_bounds\n```\n:::\n\n\n:::\n\n## Downloading the Data\n\nNow we can download specific data types for our study area. The function handles all the cloud connectivity and spatial filtering automatically.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download places data for Albany\noverture_data(albany_bbox, \"place\", \"albany_places_subset.parquet\")\n\n# Download buildings data\noverture_data(albany_bbox, \"building\", \"albany_buildings_subset.parquet\")\n\n# Download transportation segments\noverture_data(albany_bbox, \"segment\", \"albany_roads_subset.parquet\")\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Download buildings data for Manhattan\noverture_data(bbox_example, \"building\", \"nyc_buildings_subset.parquet\")\n\n# Download places data\noverture_data(bbox_example, \"place\", \"nyc_places_subset.parquet\")\n\n# Download transportation network\noverture_data(bbox_example, \"segment\", \"nyc_roads_subset.parquet\")\n```\n:::\n\n\n:::\n\n## Processing Downloaded Data\n\nAfter downloading, convert the Parquet files to spatial data formats for analysis and visualization.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the downloaded Parquet file\nalbany_places <- read_parquet(\"albany_places_subset.parquet\")\n\n# Convert to sf object for spatial operations\nalbany_places_sf <- st_as_sf(\n  albany_places |> select(-sources),\n  geometry = albany_places$geometry,\n  crs = 4326\n)\n\n# Basic data exploration\nprint(paste(\"Downloaded\", nrow(albany_places_sf), \"places\"))\nprint(colnames(albany_places_sf))\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Read the downloaded data\nmanhattan = pd.read_parquet(\"nyc_buildings_subset.parquet\")\n\n# Convert to GeoDataFrame\nmanhattan_gdf = gpd.GeoDataFrame(\n    manhattan.drop(columns=\"geometry\"),\n    geometry=shapely.wkb.loads(manhattan[\"geometry\"]),\n    crs=4326,\n)\n\n# Basic exploration\nprint(f\"Downloaded {len(manhattan_gdf)} buildings\")\nprint(manhattan_gdf.columns.tolist())\n```\n:::\n\n\n:::\n\n## Data Visualization\n\nCreate quick visualizations to explore your downloaded data and verify the results.\n\n::: {.panel-tabset}\n\n#### {{< fa brands r-project >}} R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Interactive map using tmap (equivalent to folium)\nalbany_places_sf |>\n  select(names$primary, categories$main, confidence) |>\n  tm_shape() +\n  tm_dots(col = \"categories$main\", size = 0.5, alpha = 0.8) +\n  tm_view(view.legend.position = c(\"left\", \"bottom\"))\n\n# Simple quick visualization\nalbany_places_sf |>\n  select(names$primary, categories$main, confidence) |>\n  qtm(dots.col = \"categories$main\")\n```\n:::\n\n\n#### {{< fa brands python >}} Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Static plot using GeoPandas\nmanhattan_gdf.plot(figsize=(10, 10), alpha=0.7, column='categories', legend=True)\nplt.title(\"Manhattan Buildings from Overture Maps\")\nplt.show()\n\n# Interactive map with folium (equivalent to tmap interactive)\nm = folium.Map(location=[40.7589, -73.9851], zoom_start=12)\nfolium.GeoJson(\n    manhattan_gdf.head(100),\n    popup=folium.GeoJsonPopup(fields=['names', 'categories'])\n).add_to(m)\nm\n```\n:::\n\n\n:::\n\n## Available Data Types\n\nOverture Maps provides the following data types organized by theme:\n\n| Theme | Data Types | Description |\n|-------|------------|-------------|\n| **Admins** | `locality`, `locality_area`, `administrative_boundary` | Administrative boundaries and place hierarchies |\n| **Buildings** | `building`, `building_part` | Building footprints and structural components |\n| **Places** | `place` | Points of interest, businesses, and landmarks |\n| **Transportation** | `segment`, `connector` | Road networks and transportation infrastructure |\n| **Base** | `infrastructure`, `land`, `land_use`, `water` | Base map features and land cover |\n\n## Transportation Planning Applications\n\nThis approach is particularly valuable for transportation planning workflows where you need to integrate multiple data sources for comprehensive analysis. The standardized schema and efficient spatial querying make it ideal for network analysis, land use integration, and multi-modal planning across different jurisdictions and scales.\n\n## Repository and Additional Resources\n\nThe complete code and examples are available in the [Overture Data Download repository](https://github.com/ar-puuk/overture-data-download/) on GitHub.\n\nFor more information about Overture Maps:\n\n- [Official Documentation](https://docs.overturemaps.org/)\n- [Data Schema Reference](https://docs.overturemaps.org/schema/)\n- [Community Forum](https://github.com/OvertureMaps/data/discussions)\n\n------------------------------------------------------------------------\n\n*Want to contribute or suggest improvements? Visit the project repository at:* <https://github.com/ar-puuk/overture-data-download>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}