[
  {
    "objectID": "posts/socioeconomic-demo/index.html",
    "href": "posts/socioeconomic-demo/index.html",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "",
    "text": "This section establishes the computational environment for processing socioeconomic data inputs for the Lower Savannah Council of Governments regional travel demand model using both R and Python platforms.\n\n\nThe package installation process incorporates essential libraries for comprehensive geospatial data analysis.\nThe R environment utilizes the pacman package manager to streamline the installation of multiple packages simultaneously, including tidyverse for data manipulation, sf for spatial data handling, tidycensus for Census Bureau data access, and lehdr for Longitudinal Employer-Household Dynamics data retrieval.\nThe Python environment focuses on core data science libraries including pandas for data manipulation, geopandas for spatial analysis, and pygris for Census data queries. These packages form the analytical backbone for processing demographic, employment, and geographic data required for travel demand modeling.\n\nRPython\n\n\n\n# Install and load the pacman package\nif (!require(\"pacman\")) {\n  install.packages(\"pacman\")\n}\n\nLoading required package: pacman\n\nlibrary(\"pacman\") # Package Management Tool CRAN v0.5.1\n\n# Install and load multiple desired packages at once\npacman::p_load(\n  tidyverse, # Easily Install and Load the 'Tidyverse'\n  sf, # Simple Features for R\n  sfdep, # Spatial Dependence for Simple Features\n  tidycensus, # Load US Census Boundary and Attribute Data\n  lehdr, # Grab Longitudinal Employer-Household Dynamics (LEHD)\n  arcgis, # ArcGIS Location Services Meta-Package\n  mapview, # Interactive Viewing of Spatial Data\n  RColorBrewer, # Color Palettes\n  janitor # Simple Tools for Examining and Cleaning Dirty Data\n)\n\n\n\n\n# Install required packages if not available\n# pip install numpy pandas geopandas matplotlib seaborn folium pathlib zipfile requests urllib warnings pygris\n\n# Data and Visualization\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\n\n# Query online data\nfrom pathlib import Path\nimport zipfile\nimport requests\nimport urllib.parse\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Census data query\nimport os\nfrom pygris import blocks, block_groups\nfrom pygris.helpers import validate_state, validate_county\nfrom pygris.data import get_census, get_lodes\n\n\n\n\n\n\n\nConfiguration settings optimize performance and establish spatial consistency. The tigris cache prevents redundant TIGER/Line shapefile downloads. The South Carolina State Plane coordinate system (EPSG:3361) serves as the standard projection for accurate GIS operations\n\nRPython\n\n\n\n# Set options\noptions(tigris_use_cache = TRUE) # cache tiger/line shapefile for future use\n\n# set project CRS\nproject_crs &lt;- \"EPSG:3361\"\n\n\n\n\n# Set project CRS\nproject_crs = \"EPSG:3361\"\n\n\n\n\n\n\n\nAPI authentication enables access to detailed demographic and economic datasets from the Census Bureau. The key configuration supports both R and Python environments for automated data retrieval workflows.\n\nðŸ’¡ Need a Census API key? Get one for free at census.gov/developers\n\n\nRPython\n\n\n\n# Set your API key into environment\ntidycensus::census_api_key(\"your_api_key_here\", install = TRUE)\n\n\n\n\n# Set your API key into environment\nos.environ['CENSUS_API_KEY'] = 'your_api_key_here'\n\n\n\n\n\n\n\nThe centralized directory structure organizes input data, processing files, and model outputs. The standardized root folder path ensures consistent file management across computing environments and team members.\n\nRPython\n\n\n\n# Set your main data folder\nroot &lt;- \"M:/MA_Project/SC_LSCOG LRTP\"\n\n\n\n\n# Set your main data folder\nroot = \"M:/MA_Project/SC_LSCOG LRTP\""
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#install-and-load-packages",
    "href": "posts/socioeconomic-demo/index.html#install-and-load-packages",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "",
    "text": "The package installation process incorporates essential libraries for comprehensive geospatial data analysis.\nThe R environment utilizes the pacman package manager to streamline the installation of multiple packages simultaneously, including tidyverse for data manipulation, sf for spatial data handling, tidycensus for Census Bureau data access, and lehdr for Longitudinal Employer-Household Dynamics data retrieval.\nThe Python environment focuses on core data science libraries including pandas for data manipulation, geopandas for spatial analysis, and pygris for Census data queries. These packages form the analytical backbone for processing demographic, employment, and geographic data required for travel demand modeling.\n\nRPython\n\n\n\n# Install and load the pacman package\nif (!require(\"pacman\")) {\n  install.packages(\"pacman\")\n}\n\nLoading required package: pacman\n\nlibrary(\"pacman\") # Package Management Tool CRAN v0.5.1\n\n# Install and load multiple desired packages at once\npacman::p_load(\n  tidyverse, # Easily Install and Load the 'Tidyverse'\n  sf, # Simple Features for R\n  sfdep, # Spatial Dependence for Simple Features\n  tidycensus, # Load US Census Boundary and Attribute Data\n  lehdr, # Grab Longitudinal Employer-Household Dynamics (LEHD)\n  arcgis, # ArcGIS Location Services Meta-Package\n  mapview, # Interactive Viewing of Spatial Data\n  RColorBrewer, # Color Palettes\n  janitor # Simple Tools for Examining and Cleaning Dirty Data\n)\n\n\n\n\n# Install required packages if not available\n# pip install numpy pandas geopandas matplotlib seaborn folium pathlib zipfile requests urllib warnings pygris\n\n# Data and Visualization\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\n\n# Query online data\nfrom pathlib import Path\nimport zipfile\nimport requests\nimport urllib.parse\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Census data query\nimport os\nfrom pygris import blocks, block_groups\nfrom pygris.helpers import validate_state, validate_county\nfrom pygris.data import get_census, get_lodes"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#set-global-options-and-parameters",
    "href": "posts/socioeconomic-demo/index.html#set-global-options-and-parameters",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "",
    "text": "Configuration settings optimize performance and establish spatial consistency. The tigris cache prevents redundant TIGER/Line shapefile downloads. The South Carolina State Plane coordinate system (EPSG:3361) serves as the standard projection for accurate GIS operations\n\nRPython\n\n\n\n# Set options\noptions(tigris_use_cache = TRUE) # cache tiger/line shapefile for future use\n\n# set project CRS\nproject_crs &lt;- \"EPSG:3361\"\n\n\n\n\n# Set project CRS\nproject_crs = \"EPSG:3361\""
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#set-census-api-key",
    "href": "posts/socioeconomic-demo/index.html#set-census-api-key",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "",
    "text": "API authentication enables access to detailed demographic and economic datasets from the Census Bureau. The key configuration supports both R and Python environments for automated data retrieval workflows.\n\nðŸ’¡ Need a Census API key? Get one for free at census.gov/developers\n\n\nRPython\n\n\n\n# Set your API key into environment\ntidycensus::census_api_key(\"your_api_key_here\", install = TRUE)\n\n\n\n\n# Set your API key into environment\nos.environ['CENSUS_API_KEY'] = 'your_api_key_here'"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#project-folder",
    "href": "posts/socioeconomic-demo/index.html#project-folder",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "",
    "text": "The centralized directory structure organizes input data, processing files, and model outputs. The standardized root folder path ensures consistent file management across computing environments and team members.\n\nRPython\n\n\n\n# Set your main data folder\nroot &lt;- \"M:/MA_Project/SC_LSCOG LRTP\"\n\n\n\n\n# Set your main data folder\nroot = \"M:/MA_Project/SC_LSCOG LRTP\""
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#define-state-and-counties",
    "href": "posts/socioeconomic-demo/index.html#define-state-and-counties",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "2.1 Define state and counties",
    "text": "2.1 Define state and counties\nThe study area encompasses six counties within South Carolina: Aiken, Allendale, Bamberg, Barnwell, Calhoun, and Orangeburg. These counties constitute the LSCOG planning region for travel demand modeling purposes.\n\nRPython\n\n\n\n# Define state abbreviation and county names\nstate_abb &lt;- \"SC\"\ncounty_names &lt;- c(\n  \"Aiken\",\n  \"Allendale\",\n  \"Bamberg\",\n  \"Barnwell\",\n  \"Calhoun\",\n  \"Orangeburg\"\n)\n\n\n\n\n# Define state abbreviation and county names\nstate_abb = \"SC\"\ncounty_names = [\n    \"Aiken\",\n    \"Allendale\",\n    \"Bamberg\",\n    \"Barnwell\",\n    \"Calhoun\",\n    \"Orangeburg\"\n]\n\n\n\n\nFIPS code conversion translates state abbreviations and county names into standardized Federal Information Processing Standard codes. These codes enable consistent data retrieval across census datasets and ensure proper geographic matching with demographic and economic data sources.\n\nRPython\n\n\n\n# converting state abbreviation code to FIPS code\nstate_fips &lt;- tidycensus:::validate_state(state = state_abb)\ncounty_fips &lt;- vapply(\n  county_names,\n  function(x) tidycensus:::validate_county(state = state_abb, county = x),\n  character(1)\n)\n\n# converting County Names to FIPS code\nfips_codes &lt;- paste(state_fips, county_fips, sep = \"\")\nfips_codes\n\n[1] \"45003\" \"45005\" \"45009\" \"45011\" \"45017\" \"45075\"\n\n\n\n\n\n# Converting state abbreviation code to FIPS code\nstate_fips = validate_state(state_abb)\n\nUsing FIPS code '45' for input 'SC'\n\n# Converting County Names to FIPS code\ncounty_fips = [\n    validate_county(state_fips, county)\n    for county in county_names\n]\n\nUsing FIPS code '003' for input 'Aiken'\nUsing FIPS code '005' for input 'Allendale'\nUsing FIPS code '009' for input 'Bamberg'\nUsing FIPS code '011' for input 'Barnwell'\nUsing FIPS code '017' for input 'Calhoun'\nUsing FIPS code '075' for input 'Orangeburg'\n\n# Converting County Names to FIPS code\nfips_codes = [f\"{state_fips}{county}\" for county in county_fips]\nfips_codes\n\n['45003', '45005', '45009', '45011', '45017', '45075']"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#load-taz-geometry",
    "href": "posts/socioeconomic-demo/index.html#load-taz-geometry",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "2.2 Load TAZ geometry",
    "text": "2.2 Load TAZ geometry\nThe TAZ shapefile provides the fundamental spatial framework for travel demand modeling. The geometry is loaded from the TDM exports geodatabase and filtered to include only zones within the six-county study area using FIPS code matching.\nCoordinate transformation converts the TAZ geometry to the projectâ€™s standard coordinate reference system (EPSG:3361) for accurate spatial calculations. The attribute selection retains essential fields including TAZ identifiers, area measurements, area type classifications, and county assignments.\n\nRPython\n\n\n\n# Load TAZ Shapefile\nlscog_taz &lt;- sf::read_sf(\n  file.path(root, \"GIS/data_temp/TDM Exports/TDM_Exports.gdb\"),\n  query = paste0(\n    \"SELECT * FROM \\\"SE_2019_AD_10_30_2023\\\" WHERE countyID IN (\",\n    paste0(\"'\", fips_codes, \"'\", collapse = \", \"),\n    \")\"\n  )\n) |&gt;\n  sf::st_transform(project_crs) |&gt;\n  dplyr::select(\n    ID,\n    Area,\n    Acres,\n    TAZ_ID = TAZ_IDs,\n    AREA_TYPE,\n    COUNTY,\n    COUNTYID = countyID\n  )\n\nlscog_taz\n\nSimple feature collection with 585 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1691490 ymin: 331894 xmax: 2237471 ymax: 744679.9\nProjected CRS: NAD83(HARN) / South Carolina (ft)\n# A tibble: 585 Ã— 8\n         ID  Area  Acres   TAZ_ID AREA_TYPE COUNTY       COUNTYID\n      &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;           &lt;int&gt;\n 1  9050130 13.3   8518.  9050130 RURAL     Bamberg SC      45009\n 2  9050132 39.2  25084.  9050132 RURAL     Bamberg SC      45009\n 3 75050131  9.03  5778. 75050131 RURAL     Orangeburg S    45075\n 4 75050045 15.5   9934. 75050045 RURAL     Orangeburg S    45075\n 5 75050182 17.5  11216. 75050182 SUBURBAN  Orangeburg S    45075\n 6 75050183 12.8   8191. 75050183 RURAL     Orangeburg S    45075\n 7 75050172  8.10  5181. 75050172 SUBURBAN  Orangeburg S    45075\n 8 75050204 13.4   8568. 75050204 SUBURBAN  Orangeburg S    45075\n 9 75050200  6.00  3843. 75050200 SUBURBAN  Orangeburg S    45075\n10 75050201  5.06  3239. 75050201 SUBURBAN  Orangeburg S    45075\n# â„¹ 575 more rows\n# â„¹ 1 more variable: SHAPE &lt;MULTIPOLYGON [foot]&gt;\n\n\n\n\n\n# Load TAZ Shapefile\nlscog_taz = gpd.read_file(\n    Path(root) / \"GIS/data_temp/TDM Exports/TDM_Exports.gdb\",\n    layer=\"SE_2019_AD_10_30_2023\",\n    where=f\"countyID IN ({', '.join([f\"'{fips}'\" for fips in fips_codes])})\"\n)\n\nlscog_taz = lscog_taz.to_crs(project_crs)\n\nlscog_taz = lscog_taz.rename(\n  columns={\n    'TAZ_IDs': 'TAZ_ID',\n    'countyID': 'COUNTYID'\n})[['ID', 'Area', 'Acres', 'TAZ_ID', 'AREA_TYPE', 'COUNTY', 'COUNTYID', 'geometry']]\n\nlscog_taz\n\n           ID  ...                                           geometry\n0     9050130  ...  MULTIPOLYGON (((2046194.08 478862.054, 2046134...\n1     9050132  ...  MULTIPOLYGON (((2012593.472 500179.47, 2013190...\n2    75050131  ...  MULTIPOLYGON (((2056266.071 515975.986, 205617...\n3    75050045  ...  MULTIPOLYGON (((2061826.693 488917.873, 206173...\n4    75050182  ...  MULTIPOLYGON (((2154221.857 534929.221, 215441...\n..        ...  ...                                                ...\n580   5050049  ...  MULTIPOLYGON (((1924248.136 433664.04, 1924004...\n581   5050055  ...  MULTIPOLYGON (((1905461.23 427627.626, 1905456...\n582   5050066  ...  MULTIPOLYGON (((1880812.362 414251.546, 188090...\n583   5050054  ...  MULTIPOLYGON (((1871871.454 413403.458, 187167...\n584   5050065  ...  MULTIPOLYGON (((1849074.015 398566.33, 1849218...\n\n[585 rows x 8 columns]\n\n\n\n\n\nThe interactive map visualization displays the TAZ structure colored by county, providing spatial context for the analysis area and enabling quality assurance of the geometric data loading process.\n\nRPython\n\n\n\n# Create interactive map\nmapview::mapview(lscog_taz, zcol = \"COUNTY\", lwd = 1.6, map.types = \"CartoDB.Positron\", col.regions = RColorBrewer::brewer.pal(6, \"Dark2\"))\n\n\n\n\n\n\n\n\n# Create interactive map\nlscog_taz.explore(column=\"COUNTY\", categorical=True, legend=True, tiles=\"CartoDB positron\", zoom_start=8)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#decennial-census",
    "href": "posts/socioeconomic-demo/index.html#decennial-census",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "3.1 2020 Decennial census",
    "text": "3.1 2020 Decennial census\nThe 2020 Decennial Census provides population and housing data at the census block level, offering the finest spatial resolution for demographic analysis. Population variables include total population, group quarters population, and household population derived by subtraction. Housing variables encompass total dwelling units and household counts by size categories.\nHousehold size distributions are consolidated into four categories: 1-person, 2-person, 3-person, and 4-or-more-person households. The 4-or-more category aggregates larger household sizes to simplify model implementation while maintaining essential demographic stratification for trip generation analysis.\n\nRPython\n\n\n\n# Define variables to download\ndec_variables &lt;- c(\n    TOTPOP = \"P1_001N\", # Total Population\n    GQPOP = \"P18_001N\", # Population living in Group Quarters\n    DU = \"H1_001N\", # Dwelling Units\n    HH_1 = \"H9_002N\", # 1-person household\n    HH_2 = \"H9_003N\", # 2-person household\n    HH_3 = \"H9_004N\", # 3-person household\n    # HH_4 = \"H9_005N\", # 4-person household\n    # HH_5 = \"H9_006N\", # 5-person household\n    # HH_6 = \"H9_007N\", # 6-person household\n    # HH_7 = \"H9_008N\", # 7-or-more-person household\n    HH = \"H9_001N\" # Total Number of Households\n  )\n\n# Load Population and Household Data\nlscog_dec &lt;- tidycensus::get_decennial(\n  year = 2020,\n  sumfile = \"dhc\",\n  geography = \"block\",\n  state = state_abb,\n  county = county_names,\n  output = \"wide\",\n  cb = FALSE,\n  geometry = TRUE,\n  keep_geo_vars = TRUE,\n  # key = Sys.getenv('CENSUS_API_KEY'),\n  variables = dec_variables\n) |&gt;\n  sf::st_transform(project_crs) |&gt;\n  dplyr::mutate(\n    HHPOP = TOTPOP - GQPOP,\n    HH_4 = HH - (HH_1 + HH_2 + HH_3)\n  ) |&gt;\n  dplyr::select(GEOID, TOTPOP, GQPOP, HHPOP, HH, HH_1, HH_2, HH_3, HH_4, DU)\n\nGetting data from the 2020 decennial Census\n\n\nUsing the Demographic and Housing Characteristics File\n\n\nNote: 2020 decennial Census data use differential privacy, a technique that\nintroduces errors into data to preserve respondent confidentiality.\nâ„¹ Small counts should be interpreted with caution.\nâ„¹ See https://www.census.gov/library/fact-sheets/2021/protecting-the-confidentiality-of-the-2020-census-redistricting-data.html for additional guidance.\nThis message is displayed once per session.\n\nlscog_dec\n\nSimple feature collection with 13961 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1691517 ymin: 331891.7 xmax: 2237472 ymax: 744669.5\nProjected CRS: NAD83(HARN) / South Carolina (ft)\n# A tibble: 13,961 Ã— 11\n   GEOID           TOTPOP GQPOP HHPOP    HH  HH_1  HH_2  HH_3  HH_4    DU\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 450179504004051      0     0     0     0     0     0     0     0     0\n 2 450179504003011      0     0     0     0     0     0     0     0     0\n 3 450179502011045     54     4    50    16     3     1     3     9    18\n 4 450179504001020      0     0     0     0     0     0     0     0     0\n 5 450750105003029     13     0    13     4     0     3     0     1     4\n 6 450750117021009     10     0    10     3     3     0     0     0     8\n 7 450750117011051      0     0     0     0     0     0     0     0     0\n 8 450750118021087      6     0     6     4     0     1     2     1     4\n 9 450750120003020      0     0     0     0     0     0     0     0     0\n10 450179501003046     18     0    18     0     0     0     0     0     1\n# â„¹ 13,951 more rows\n# â„¹ 1 more variable: geometry &lt;MULTIPOLYGON [foot]&gt;\n\n\n\n\n\n# Define variables to download\ndec_variables = {\n    'P1_001N': 'TOTPOP',     # Total Population\n    'P18_001N': 'GQPOP',      # Population living in Group Quarters\n    'H1_001N': 'DU',          # Dwelling Units\n    'H9_002N': 'HH_1',        # 1-person household\n    'H9_003N': 'HH_2',        # 2-person household\n    'H9_004N': 'HH_3',        # 3-person household\n    # 'H9_005N': 'HH_4',        # 4-person household\n    # 'H9_006N': 'HH_5',        # 5-person household\n    # 'H9_007N': 'HH_6',        # 6-person household\n    # 'H9_008N': 'HH_7',        # 7-or-more-person household\n    'H9_001N': 'HH'           # Total Number of Households\n}\n\n# get census block geometries\nlscog_cb = blocks(\n    state=state_fips,\n    county=county_fips,\n    year=2020,\n    cache=True\n)\n\n# Download decennial census data at block level\nlscog_dec = get_census(\n    dataset=\"dec/dhc\",\n    year=2020,\n    variables=list(dec_variables.keys()),\n    params={\n        \"for\": f\"block:*\",\n        # \"key\": f\"{os.getenv('CENSUS_API_KEY')}\",\n        \"in\": f\"state:{state_fips} county:{','.join(county_fips)}\"\n    },\n    return_geoid=True,\n    guess_dtypes=True,\n)\n\n# join data to geometry\nlscog_dec = lscog_cb[['GEOID20', 'geometry']].merge(lscog_dec, left_on = \"GEOID20\", right_on = \"GEOID\")\n\n# Rename columns\nlscog_dec = lscog_dec.rename(columns=dec_variables)\n\n# Transform CRS\nlscog_dec = lscog_dec.to_crs(project_crs)\n\n# Calculate derived variables\nlscog_dec['HHPOP'] = lscog_dec['TOTPOP'] - lscog_dec['GQPOP']\nlscog_dec['HH_4'] = lscog_dec['HH'] - (\n    lscog_dec['HH_1'] + lscog_dec['HH_2'] + lscog_dec['HH_3']\n)\n\n# Select final columns\nlscog_dec = lscog_dec[['GEOID', 'TOTPOP', 'GQPOP', 'HHPOP',\n                      'HH', 'HH_1', 'HH_2', 'HH_3', 'HH_4', 'DU', 'geometry']]\n\nlscog_dec\n\n                 GEOID  ...                                           geometry\n0      450179504004051  ...  POLYGON ((2084300.974 622308.526, 2084460.74 6...\n1      450179504003011  ...  POLYGON ((2112518.54 626782.208, 2112608.778 6...\n2      450179502011045  ...  POLYGON ((2067775.167 662339.483, 2068091.491 ...\n3      450179504001020  ...  POLYGON ((2087947.053 684345.612, 2087992.284 ...\n4      450750105003029  ...  POLYGON ((2089072.743 552687.443, 2089248.831 ...\n...                ...  ...                                                ...\n13956  450059705003050  ...  POLYGON ((1926607.333 409005.466, 1926609.861 ...\n13957  450030203042000  ...  POLYGON ((1778751.197 641782.585, 1778797.329 ...\n13958  450030218002115  ...  POLYGON ((1919787.314 648288.439, 1919913.531 ...\n13959  450030206012008  ...  POLYGON ((1723756.559 630234.507, 1723784.384 ...\n13960  450059705002005  ...  POLYGON ((1926817.622 432583.896, 1930423.825 ...\n\n[13961 rows x 11 columns]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#acs-estimates",
    "href": "posts/socioeconomic-demo/index.html#acs-estimates",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "3.2 2020 ACS estimates",
    "text": "3.2 2020 ACS estimates\nThe American Community Survey 5-year estimates provide household income data at the block group level. Income categories are aggregated into three broad ranges: under $15,000, $15,000-$49,999, and $50,000 and above. This stratification aligns with travel behavior research indicating distinct mobility patterns across income levels.\nThe block group geography represents the finest spatial resolution available for ACS income data, providing sufficient detail for socioeconomic modeling while maintaining statistical reliability through the 5-year aggregation period.\n\nRPython\n\n\n\n# Define variables to download\nacs_variables &lt;- c(\n    INC_CAT_02 = \"B19001_002\", # Less than $10,000\n    INC_CAT_03 = \"B19001_003\", # $10,000 to $14,999\n    INC_CAT_04 = \"B19001_004\", # $15,000 to $19,999\n    INC_CAT_05 = \"B19001_005\", # $20,000 to $24,999\n    INC_CAT_06 = \"B19001_006\", # $25,000 to $29,999\n    INC_CAT_07 = \"B19001_007\", # $30,000 to $34,999\n    INC_CAT_08 = \"B19001_008\", # $35,000 to $39,999\n    INC_CAT_09 = \"B19001_009\", # $40,000 to $44,999\n    INC_CAT_10 = \"B19001_010\", # $45,000 to $49,999\n    # INC_CAT_11 = \"B19001_011\", # $50,000 to $59,999\n    # INC_CAT_12 = \"B19001_012\", # $60,000 to $74,999\n    # INC_CAT_13 = \"B19001_013\", # $75,000 to $99,999\n    # INC_CAT_14 = \"B19001_014\", # $100,000 to $124,999\n    # INC_CAT_15 = \"B19001_015\", # $125,000 to $149,999\n    # INC_CAT_16 = \"B19001_016\", # $150,000 to $199,999\n    # INC_CAT_17 = \"B19001_017\", # $200,000 or more\n    INC_CAT_01 = \"B19001_001\" # Total\n  )\n\n# Load Household Income Data\nlscog_acs &lt;- tidycensus::get_acs(\n  year = 2020,\n  survey = \"acs5\",\n  geography = \"block group\",\n  state = state_fips,\n  county = county_fips,\n  output = \"wide\",\n  cb = FALSE,\n  geometry = TRUE,\n  # key = Sys.getenv('CENSUS_API_KEY'),\n  variables = acs_variables\n) |&gt;\n  sf::st_transform(project_crs) |&gt;\n  dplyr::mutate(\n    INC_14999 = INC_CAT_02E + INC_CAT_03E,\n    INC_49999 = INC_CAT_04E +\n      INC_CAT_05E +\n      INC_CAT_06E +\n      INC_CAT_07E +\n      INC_CAT_08E +\n      INC_CAT_09E +\n      INC_CAT_10E,\n    INC_50000 = INC_CAT_01E - (INC_14999 + INC_49999)\n  ) |&gt;\n  dplyr::select(GEOID, INC_TOTAL = INC_CAT_01E, INC_14999, INC_49999, INC_50000)\n\nGetting data from the 2016-2020 5-year ACS\n\nlscog_acs\n\nSimple feature collection with 262 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1691517 ymin: 331891.7 xmax: 2237472 ymax: 744669.5\nProjected CRS: NAD83(HARN) / South Carolina (ft)\nFirst 10 features:\n          GEOID INC_TOTAL INC_14999 INC_49999 INC_50000\n1  450030207011       467        82       171       214\n2  450030212052       949         0       256       693\n3  450030212051       857        21       250       586\n4  450030213001       612       103       129       380\n5  450030216031      1191       176       303       712\n6  450030215003       773        95       240       438\n7  450030205004      1081        56       302       723\n8  450030205003       937        37       158       742\n9  450030212041       758        37       344       377\n10 450030215004       973        77       247       649\n                         geometry\n1  MULTIPOLYGON (((1701402 614...\n2  MULTIPOLYGON (((1776367 591...\n3  MULTIPOLYGON (((1768340 598...\n4  MULTIPOLYGON (((1768476 630...\n5  MULTIPOLYGON (((1785900 618...\n6  MULTIPOLYGON (((1782074 620...\n7  MULTIPOLYGON (((1707972 630...\n8  MULTIPOLYGON (((1708123 634...\n9  MULTIPOLYGON (((1775528 610...\n10 MULTIPOLYGON (((1779272 619...\n\n\n\n\n\n# Define variables to download\nacs_variables = {\n    'B19001_002E': 'INC_CAT_02',  # Less than $10,000\n    'B19001_003E': 'INC_CAT_03',  # $10,000 to $14,999\n    'B19001_004E': 'INC_CAT_04',  # $15,000 to $19,999\n    'B19001_005E': 'INC_CAT_05',  # $20,000 to $24,999\n    'B19001_006E': 'INC_CAT_06',  # $25,000 to $29,999\n    'B19001_007E': 'INC_CAT_07',  # $30,000 to $34,999\n    'B19001_008E': 'INC_CAT_08',  # $35,000 to $39,999\n    'B19001_009E': 'INC_CAT_09',  # $40,000 to $44,999\n    'B19001_010E': 'INC_CAT_10',  # $45,000 to $49,999\n    # 'B19001_011E': 'INC_CAT_11',  # $50,000 to $59,999\n    # 'B19001_012E': 'INC_CAT_12',  # $60,000 to $74,999\n    # 'B19001_013E': 'INC_CAT_13',  # $75,000 to $99,999\n    # 'B19001_014E': 'INC_CAT_14',  # $100,000 to $124,999\n    # 'B19001_015E': 'INC_CAT_15',  # $125,000 to $149,999\n    # 'B19001_016E': 'INC_CAT_16',  # $150,000 to $199,999\n    # 'B19001_017E': 'INC_CAT_17',  # $200,000 or more\n    'B19001_001E': 'INC_CAT_01'   # Total\n}\n\n# get blockgroup geometries\nlscog_bg = block_groups(\n    state=state_fips,\n    county=county_fips,\n    year=2020,\n    cache=True\n)\n\n# Download household income data at block group level\nlscog_acs = get_census(\n    dataset=\"acs/acs5\",\n    year=2020,\n    variables=list(acs_variables.keys()),\n    params={\n        \"for\": f\"block group:*\",\n        # \"key\": f\"{os.getenv('CENSUS_API_KEY')}\",\n        \"in\": f\"state:{state_fips} county:{','.join(county_fips)}\"\n    },\n    return_geoid=True,\n    guess_dtypes=True\n)\n\n# join data to geometry\nlscog_acs = lscog_bg[['GEOID', 'geometry']].merge(lscog_acs, on = \"GEOID\")\n\n# Rename columns\nlscog_acs = lscog_acs.rename(columns=acs_variables)\n\n# Transform CRS\nlscog_acs = lscog_acs.to_crs(project_crs)\n\n# Calculate derived variables\nlscog_acs['INC_14999'] = lscog_acs['INC_CAT_02'] + lscog_acs['INC_CAT_03']\nlscog_acs['INC_49999'] = (\n    lscog_acs['INC_CAT_04'] +\n    lscog_acs['INC_CAT_05'] +\n    lscog_acs['INC_CAT_06'] +\n    lscog_acs['INC_CAT_07'] +\n    lscog_acs['INC_CAT_08'] +\n    lscog_acs['INC_CAT_09'] +\n    lscog_acs['INC_CAT_10']\n)\nlscog_acs['INC_50000'] = lscog_acs['INC_CAT_01'] - (\n    lscog_acs['INC_14999'] + lscog_acs['INC_49999']\n)\n\n# Select final columns\nlscog_acs = lscog_acs.rename(columns={'INC_CAT_01': 'INC_TOTAL'})\nlscog_acs = lscog_acs[['GEOID', 'INC_TOTAL', 'INC_14999', 'INC_49999', 'INC_50000', 'geometry'\n]]\n\nlscog_acs\n\n            GEOID  ...                                           geometry\n0    450030207011  ...  POLYGON ((1701402.37 614608.958, 1701441.07 61...\n1    450030212052  ...  POLYGON ((1776366.684 591083.944, 1776445.37 5...\n2    450030212051  ...  POLYGON ((1768340.248 598546.468, 1768482.141 ...\n3    450030213001  ...  POLYGON ((1768475.931 630588.733, 1768610.076 ...\n4    450030216031  ...  POLYGON ((1785900.107 618251.028, 1786047.488 ...\n..            ...  ...                                                ...\n257  450750119004  ...  POLYGON ((1974249.527 620700.361, 1975105.197 ...\n258  450750103011  ...  POLYGON ((2142864.631 581695.327, 2142874.033 ...\n259  450750109011  ...  POLYGON ((2033500.16 608479.774, 2033509.304 6...\n260  450750109022  ...  POLYGON ((2013478.807 622487.426, 2013488.515 ...\n261  450750109023  ...  POLYGON ((2022268.105 617836.647, 2022656.655 ...\n\n[262 rows x 6 columns]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#lehd-data",
    "href": "posts/socioeconomic-demo/index.html#lehd-data",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "3.3 2019 LEHD data",
    "text": "3.3 2019 LEHD data\nThe Longitudinal Employer-Household Dynamics Workplace Area Characteristics data provides employment counts by industry sector at the census block level. Employment categories follow the North American Industry Classification System and are aggregated into transportation-relevant sectors including retail, services, manufacturing, and public administration.\nThe 2019 reference year represents pre-pandemic employment patterns, providing a stable baseline for long-term transportation planning. Employment data at the block level enables precise spatial allocation of work destinations within the travel demand model framework.\n\nRPython\n\n\n\n# Download LEHD WAC data at block level\nlscog_emp &lt;- lehdr::grab_lodes(\n  version = \"LODES8\",\n  state = tolower(state_abb),\n  lodes_type = \"wac\",\n  segment = \"S000\",\n  job_type = \"JT00\",\n  year = 2019,\n  state_part = \"\",\n  agg_geo = \"block\",\n  use_cache = TRUE\n) |&gt;\n  dplyr::filter(grepl(\n    paste(\"^(\", paste(fips_codes, collapse = \"|\"), \")\", sep = \"\"),\n    w_geocode\n  )) |&gt;\n  # check the documentation at: https://lehd.ces.census.gov/data/lodes/LODES8/LODESTechDoc8.0.pdf\n  dplyr::mutate(\n    GEOID = as.character(w_geocode),\n    TOTAL_EMP = C000, # Total Employment\n    AGR_FOR_FI = CNS01, # Agricultural, forestry, and fishing employment\n    MINING = CNS02, # Mining employment\n    CONSTRUCTI = CNS04, # Construction employment\n    MANUFACTUR = CNS05, # Manufacturing employment\n    TRANSP_COM = CNS08 + CNS09, # Transportation, communication employment\n    WHOLESALE = CNS06, # Wholesale employment\n    RETAIL = CNS07, # Retail employment\n    FIRE = CNS10 + CNS11, # Finance / Insurance / Real Estate employment\n    SERVICES = CNS03 +\n      CNS12 +\n      CNS13 +\n      CNS14 + # Service employment\n      CNS15 +\n      CNS16 +\n      CNS17 +\n      CNS18 +\n      CNS19,\n    PUBLIC_ADM = CNS20 # Public Administration employment\n  ) |&gt;\n  dplyr::select(\n    GEOID,\n    TOTAL_EMP,\n    AGR_FOR_FI,\n    MINING,\n    CONSTRUCTI,\n    MANUFACTUR,\n    TRANSP_COM,\n    WHOLESALE,\n    RETAIL,\n    FIRE,\n    SERVICES,\n    PUBLIC_ADM\n  )\n\nUsing cached version of file found in:\nC:\\Users\\pukar\\AppData\\Local\\R\\cache\\R\\lehdr\\sc_wac_S000_JT00_2019.csv.gz\n\nlscog_emp\n\n# A tibble: 2,450 Ã— 12\n   GEOID  TOTAL_EMP AGR_FOR_FI MINING CONSTRUCTI MANUFACTUR TRANSP_COM WHOLESALE\n   &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 45003â€¦         6          6      0          0          0          0         0\n 2 45003â€¦         4          0      0          0          0          4         0\n 3 45003â€¦        12          0      0         12          0          0         0\n 4 45003â€¦         1          0      0          0          0          0         0\n 5 45003â€¦        11         11      0          0          0          0         0\n 6 45003â€¦         1          0      0          0          0          0         0\n 7 45003â€¦         9          0      0          0          0          0         0\n 8 45003â€¦        18          0      0         18          0          0         0\n 9 45003â€¦         1          0      0          1          0          0         0\n10 45003â€¦         4          4      0          0          0          0         0\n# â„¹ 2,440 more rows\n# â„¹ 4 more variables: RETAIL &lt;dbl&gt;, FIRE &lt;dbl&gt;, SERVICES &lt;dbl&gt;,\n#   PUBLIC_ADM &lt;dbl&gt;\n\n\n\n\n\n# Download LEHD WAC data at block level\nlscog_emp = get_lodes(\n    state=state_abb,\n    year=2019,\n    version=\"LODES8\",\n    lodes_type=\"wac\",\n    part=\"main\",\n    segment=\"S000\",\n    job_type=\"JT00\",\n    agg_level=\"block\",\n    cache=True,\n    return_geometry=True\n)\n\nRequesting feature geometry.\nUsing FIPS code '45' for input 'sc'\n\n# Filter for specific FIPS codes\nlscog_emp = lscog_emp[lscog_emp['w_geocode'].str.match(f\"^({'|'.join(fips_codes)})\")]\n\n# Create new columns with employment categories\n# Check documentation at: https://lehd.ces.census.gov/data/lodes/LODES8/LODESTechDoc8.0.pdf\nlscog_emp = lscog_emp.assign(\n    GEOID=lscog_emp['w_geocode'].astype(str),\n    TOTAL_EMP=lscog_emp['C000'],  # Total Employment\n    AGR_FOR_FI=lscog_emp['CNS01'],  # Agricultural, forestry, and fishing employment\n    MINING=lscog_emp['CNS02'],  # Mining employment\n    CONSTRUCTI=lscog_emp['CNS04'],  # Construction employment\n    MANUFACTUR=lscog_emp['CNS05'],  # Manufacturing employment\n    TRANSP_COM=lscog_emp['CNS08'] + lscog_emp['CNS09'],  # Transportation, communication employment\n    WHOLESALE=lscog_emp['CNS06'],  # Wholesale employment\n    RETAIL=lscog_emp['CNS07'],  # Retail employment\n    FIRE=lscog_emp['CNS10'] + lscog_emp['CNS11'],  # Finance / Insurance / Real Estate employment\n    SERVICES=(lscog_emp['CNS03'] +\n              lscog_emp['CNS12'] +\n              lscog_emp['CNS13'] +\n              lscog_emp['CNS14'] +\n              lscog_emp['CNS15'] +\n              lscog_emp['CNS16'] +\n              lscog_emp['CNS17'] +\n              lscog_emp['CNS18'] +\n              lscog_emp['CNS19']),  # Service employment\n    PUBLIC_ADM=lscog_emp['CNS20']  # Public Administration employment\n)\n\n# Transform CRS\nlscog_emp = lscog_emp.to_crs(project_crs)\n\n# Select only the desired columns\nlscog_emp = lscog_emp[['GEOID', 'TOTAL_EMP', 'AGR_FOR_FI', 'MINING', 'CONSTRUCTI',\n                       'MANUFACTUR', 'TRANSP_COM', 'WHOLESALE', 'RETAIL', 'FIRE',\n                       'SERVICES', 'PUBLIC_ADM']]\n\n# Display structure/info about the dataframe\nlscog_emp\n\n                 GEOID  TOTAL_EMP  AGR_FOR_FI  ...  FIRE  SERVICES  PUBLIC_ADM\n44     450750104003025         65           0  ...     0        65           0\n71     450179504004029         38           0  ...     0         0           8\n108    450750103021014          2           0  ...     0         2           0\n136    450750113001053         65           0  ...     0        27           0\n141    450750110003002         18           0  ...    16         2           0\n...                ...        ...         ...  ...   ...       ...         ...\n36888  450179501003024         90           0  ...     0         7           0\n36896  450750109022000         20           0  ...     3        15           0\n36919  450059702012046          6           0  ...     6         0           0\n36966  450059702022044          8           8  ...     0         0           0\n36981  450030203041014         88           0  ...     0        76           0\n\n[2450 rows x 12 columns]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#nces-school-and-college-enrollment-data",
    "href": "posts/socioeconomic-demo/index.html#nces-school-and-college-enrollment-data",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "3.4 2020 NCES school and college enrollment data",
    "text": "3.4 2020 NCES school and college enrollment data\nThe National Center for Education Statistics provides comprehensive educational institution data including enrollment and staffing information for transportation planning analysis.\n\nPublic schools\nPublic school data is retrieved from the NCES ArcGIS REST service for the 2019-2020 academic year. The dataset includes total student enrollment and full-time equivalent teacher counts for each institution within the six-county region. Public schools represent major trip generation sources for both student and employee travel, requiring precise spatial location data for accurate modeling.\n\nRPython\n\n\n\n# Public School Location data 2019-2020\nlscog_pub_sch_enroll &lt;- arcgislayers::arc_read(\n  url = \"https://nces.ed.gov/opengis/rest/services/K12_School_Locations/EDGE_ADMINDATA_PUBLICSCH_1920/MapServer/0\",\n  where = paste0(\n    \"LSTATE = '\",\n    state_abb,\n    \"' AND NMCNTY IN (\",\n    paste0(\"'\", paste0(county_names, \" County\"), \"'\", collapse = \", \"),\n    \")\"\n  ),\n  alias = \"label\",\n  crs = project_crs\n) |&gt;\n  dplyr::select(\n    INSTITUTION_ID = NCESSCH,\n    NAME = SCH_NAME,\n    STATE = LSTATE,\n    STUDENT_COUNT_PUB = TOTAL,\n    TEACHER_COUNT_PUB = FTE\n  )\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\nlscog_pub_sch_enroll\n\nSimple feature collection with 98 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1700952 ymin: 406810.6 xmax: 2203406 ymax: 724699.4\nProjected CRS: NAD83(HARN) / South Carolina (ft)\nFirst 10 features:\n   INSTITUTION_ID                          NAME STATE STUDENT_COUNT_PUB\n1    450108001163           Barnwell Elementary    SC               462\n2    450075000064        Allendale Fairfax High    SC               283\n3    450075001184          Allendale Elementary    SC               245\n4    450075001415      Allendale-Fairfax Middle    SC               268\n5    450093000119         Bamberg-Ehrhardt High    SC               381\n6    450093000120       Bamberg-Ehrhardt Middle    SC               188\n7    450096000122             Denmark Olar High    SC               162\n8    450096000123           Denmark-Olar Middle    SC               149\n9    450096001426       Denmark-Olar Elementary    SC               353\n10   450098000127 Barnwell County Career Center    SC                 0\n   TEACHER_COUNT_PUB                 geometry\n1               32.0 POINT (1891531 517378.5)\n2               28.9 POINT (1913416 420526.6)\n3               18.0 POINT (1916344 418212.2)\n4               18.0 POINT (1913416 420526.6)\n5               28.5 POINT (1991502 535259.1)\n6               15.0 POINT (1990622 534442.6)\n7               20.0   POINT (1962410 543779)\n8               10.0 POINT (1956236 534420.3)\n9               25.0 POINT (1960237 537023.1)\n10              12.0   POINT (1894891 540093)\n\n\n\n\n\n\nCode\n# Create function to read ArcGIS FeatureLayer or Table\ndef arc_read(url, where=\"1=1\", outFields=\"*\", outSR=4326, **kwargs):\n    \"\"\"\n    Read an ArcGIS FeatureLayer or Table to a GeoDataFrame.\n\n    Parameters:\n    url (str): The ArcGIS REST service URL ending with /MapServer/0 or /FeatureServer/0\n    where (str): SQL WHERE clause for filtering. Default: \"1=1\" (all records)\n    outFields (str): Comma-separated field names or \"*\" for all fields. Default: \"*\"\n    outSR (int): Output spatial reference EPSG code. Default: 4326\n    **kwargs: Additional query parameters passed to the ArcGIS REST API\n\n    Returns:\n    geopandas.GeoDataFrame: Spatial data from the service\n    \"\"\"\n\n    # Ensure URL ends with /query\n    if not url.endswith('/query'):\n        url = url.rstrip('/') + '/query'\n\n    # Build query parameters\n    params = {\n        'where': where,\n        'outFields': outFields,\n        'returnGeometry': 'true',\n        # 'geometryType': 'esriGeometryPoint',\n        'outSR': outSR,\n        'f': 'geojson'\n    }\n\n    # Add any additional parameters\n    params.update(kwargs)\n\n    # Make request\n    response = requests.get(url, params=params)\n\n    # Read as GeoDataFrame\n    return gpd.read_file(response.text)\n\n\n\n# Public School Enrollment data 2019-2020\nlscog_pub_sch_enroll = arc_read(\n    url=\"https://nces.ed.gov/opengis/rest/services/K12_School_Locations/EDGE_ADMINDATA_PUBLICSCH_1920/MapServer/0\",\n    where=f\"LSTATE = '{state_abb}' AND NMCNTY IN ('{\"', '\".join([f\"{name} County\" for name in county_names])}')\",\n    outFields='NCESSCH,SCH_NAME,LSTATE,TOTAL,FTE'\n)\n\n# Transform CRS\nlscog_pub_sch_enroll = lscog_pub_sch_enroll.to_crs(project_crs)\n\n# Select and rename columns\nlscog_pub_sch_enroll = lscog_pub_sch_enroll.rename(columns={\n    'NCESSCH': 'INSTITUTION_ID',\n    'SCH_NAME': 'NAME',\n    'LSTATE': 'STATE',\n    'TOTAL': 'STUDENT_COUNT_PUB',\n    'FTE': 'TEACHER_COUNT_PUB'\n})\n\nlscog_pub_sch_enroll\n\n   INSTITUTION_ID  ...                        geometry\n0    450108001163  ...  POINT (1891532.112 517376.183)\n1    450075000064  ...  POINT (1913417.281 420524.266)\n2    450075001184  ...   POINT (1916345.361 418209.84)\n3    450075001415  ...  POINT (1913417.281 420524.266)\n4    450093000119  ...  POINT (1991503.106 535256.782)\n..            ...  ...                             ...\n93   450391001291  ...  POINT (2048660.583 606357.033)\n94   450391001370  ...    POINT (2040865.5 608975.982)\n95   450391001604  ...  POINT (2050404.085 617575.512)\n96   450391001693  ...    POINT (2030130.8 597632.129)\n97   450391001694  ...  POINT (2043557.083 596562.932)\n\n[98 rows x 6 columns]\n\n\n\n\n\n\n\nPrivate schools\nPrivate school enrollment data is accessed from the NCES Private School Survey archived dataset. The data is spatially enabled using latitude and longitude coordinates and filtered to include only institutions within the study area TAZ boundaries. Private schools contribute to the regional education trip matrix and must be incorporated alongside public institutions for comprehensive coverage.\n\nRPython\n\n\n\n# Private School Enrollment data 2019-2020\nlscog_pvt_sch_enroll &lt;- vroom::vroom(\n  unz(\n    file.path(\n      root,\n      \"GIS/data_external/20250315 NCES/PSS - Private/2019-20/pss1920_pu_csv.zip\"\n    ),\n    \"pss1920_pu.csv\"\n  ),\n  col_types = vroom::cols_only(\n    PPIN        = vroom::col_character(),\n    PINST       = vroom::col_character(),\n    PL_STABB    = vroom::col_character(),\n    PCNTNM      = vroom::col_character(),\n    SIZE        = vroom::col_double(),\n    NUMTEACH    = vroom::col_double(),\n    LATITUDE20  = vroom::col_double(),\n    LONGITUDE20 = vroom::col_double()\n  )\n) |&gt;\n  sf::st_as_sf(coords = c(\"LONGITUDE20\", \"LATITUDE20\"), crs = \"EPSG:4326\") |&gt;\n  sf::st_transform(project_crs) |&gt;\n  sf::st_filter(lscog_taz, .predicate = st_intersects) |&gt;\n  dplyr::select(\n    INSTITUTION_ID = PPIN,\n    NAME = PINST,\n    STATE = PL_STABB,\n    STUDENT_COUNT_PVT = SIZE,\n    TEACHER_COUNT_PVT = NUMTEACH\n  )\n\nlscog_pvt_sch_enroll\n\nSimple feature collection with 24 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1704062 ymin: 492304.2 xmax: 2179510 ymax: 720184.2\nProjected CRS: NAD83(HARN) / South Carolina (ft)\n# A tibble: 24 Ã— 6\n   INSTITUTION_ID NAME                 STATE STUDENT_COUNT_PVT TEACHER_COUNT_PVT\n   &lt;chr&gt;          &lt;chr&gt;                &lt;chr&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n 1 K9305823       AIKENS FBC PRESCHOOL SC                    1               1.3\n 2 01264947       ANDREW JACKSON ACADâ€¦ SC                    3              13.3\n 3 A9106158       BARNWELL CHRISTIAN â€¦ &lt;NA&gt;                  2               5.8\n 4 01263568       CALHOUN ACADEMY      SC                    3              26.6\n 5 A1771477       FIRST BAPTIST CHURCâ€¦ &lt;NA&gt;                  1               3.1\n 6 A9703151       FIRST PRESBYTERIAN â€¦ &lt;NA&gt;                  1               2.8\n 7 BB170334       FIRST SOUTHERN METHâ€¦ SC                    1               6  \n 8 A1102039       FOUNDATION CHRISTIAâ€¦ &lt;NA&gt;                  1               5  \n 9 A0307976       GRACE CHILD DEVELOPâ€¦ &lt;NA&gt;                  1               2.9\n10 A0307978       GREATER FAITH BAPTIâ€¦ &lt;NA&gt;                  1               1  \n# â„¹ 14 more rows\n# â„¹ 1 more variable: geometry &lt;POINT [foot]&gt;\n\n\n\n\n\n# Private School Enrollment data 2019-2020\nzip_path = Path(root) / \"GIS/data_external/20250315 NCES/PSS - Private/2019-20/pss1920_pu_csv.zip\"\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    with zip_ref.open('pss1920_pu.csv') as csv_file:\n        lscog_pvt_sch_enroll = pd.read_csv(\n            csv_file,\n            usecols=['PPIN', 'PINST', 'PL_STABB', 'PCNTNM', 'SIZE', 'NUMTEACH', 'LATITUDE20', 'LONGITUDE20'],\n            dtype={'PPIN': 'str', 'PINST': 'str', 'PL_STABB': 'str', 'PCNTNM': 'str', 'SIZE': 'float64', 'NUMTEACH': 'float64'}\n        )\n\nlscog_pvt_sch_enroll = gpd.GeoDataFrame(\n    lscog_pvt_sch_enroll,\n    geometry=gpd.points_from_xy(lscog_pvt_sch_enroll['LONGITUDE20'], lscog_pvt_sch_enroll['LATITUDE20']),\n    crs='EPSG:4326'\n).to_crs(project_crs)\n\nlscog_pvt_sch_enroll = gpd.sjoin(lscog_pvt_sch_enroll, lscog_taz, how='inner', predicate='intersects')[\n    ['PPIN', 'PINST', 'PL_STABB', 'SIZE', 'NUMTEACH', 'geometry']\n].rename(columns={\n    'PPIN': 'INSTITUTION_ID',\n    'PINST': 'NAME',\n    'PL_STABB': 'STATE',\n    'SIZE': 'STUDENT_COUNT_PVT',\n    'NUMTEACH': 'TEACHER_COUNT_PVT'\n})\n\nlscog_pvt_sch_enroll\n\n      INSTITUTION_ID  ...                        geometry\n17469       K9305823  ...  POINT (1781275.702 629440.997)\n17474       01264947  ...   POINT (1993756.78 492304.247)\n17476       A9106158  ...   POINT (1914982.59 524548.558)\n17484       01263568  ...  POINT (2072197.427 660303.544)\n17533       A1771477  ...  POINT (1704061.773 606321.234)\n17537       A9703151  ...  POINT (1780623.642 630282.337)\n17538       BB170334  ...   POINT (2037420.57 608741.769)\n17543       A1102039  ...  POINT (2006658.982 720184.199)\n17547       A0307976  ...   POINT (1704601.274 606316.17)\n17550       A0307978  ...  POINT (2047302.618 604573.723)\n17566       A1904026  ...  POINT (2179509.785 547981.083)\n17571       01263692  ...  POINT (1918041.289 549840.623)\n17599       01264754  ...  POINT (1779301.654 629488.248)\n17601       A0308015  ...  POINT (1733987.726 611499.727)\n17623       A1303185  ...   POINT (1853302.82 681159.161)\n17637       A9903938  ...   POINT (2047246.79 597082.682)\n17651       A0109147  ...  POINT (1780574.399 631607.375)\n17657       01264288  ...  POINT (1778262.542 613244.891)\n17658       K9305825  ...  POINT (1779510.666 617490.702)\n17663       K9305640  ...   POINT (2041004.71 611841.216)\n17672       A9703170  ...   POINT (1780823.53 629681.358)\n17676       01262826  ...   POINT (1781344.96 628712.135)\n17722       01932407  ...   POINT (2037497.91 608547.947)\n17733       A9903957  ...  POINT (1875514.037 565892.953)\n\n[24 rows x 6 columns]\n\n\n\n\n\n\n\nPost-secondary institutions\nPost-secondary institution locations are obtained from the NCES Postsecondary School Locations service, filtered by state and county FIPS codes. These institutions generate significant travel demand through student commuting, employee travel, and visitor trips, making them essential components of the regional transportation network analysis.\n\nRPython\n\n\n\n# Post-Secondary Location data 2019-2020\nlscog_college_loc &lt;- arcgislayers::arc_read(\n  url = \"https://nces.ed.gov/opengis/rest/services/Postsecondary_School_Locations/EDGE_GEOCODE_POSTSECONDARYSCH_1920/MapServer/0\",\n  where = paste0(\n    \"STATE = '\",\n    state_abb,\n    \"' AND CNTY IN (\",\n    paste0(\"'\", fips_codes, \"'\", collapse = \", \"),\n    \")\"\n  ),\n  alias = \"label\",\n  crs = project_crs\n)\n\nlscog_college_loc\n\nSimple feature collection with 11 features and 24 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1708029 ymin: 429827.9 xmax: 2052011 ymax: 633710.3\nProjected CRS: NAD83(HARN) / South Carolina (ft)\nFirst 10 features:\n   OBJECTID UNITID                                               NAME\n1      3411 217615                            Aiken Technical College\n2      3424 217873                                 Claflin University\n3      3431 217989                          Denmark Technical College\n4      3439 218159 Kenneth Shuler School of Cosmetology-North Augusta\n5      3448 218487               Orangeburg Calhoun Technical College\n6      3451 218645                 University of South Carolina Aiken\n7      3455 218681          University of South Carolina-Salkehatchie\n8      3459 218733                    South Carolina State University\n9      3468 218919                                   Voorhees College\n10     5829 457998          Aiken School of Cosmetology and Barbering\n                         STREET          CITY STATE        ZIP STFIP  CNTY\n1  2276 Jefferson Davis Highway  Graniteville    SC      29829    45 45003\n2           400 Magnolia Street    Orangeburg    SC 29115-4498    45 45075\n3       1126 Solomon Blatt Blvd       Denmark    SC      29042    45 45009\n4              1113 Knox Avenue North Augusta    SC      29841    45 45003\n5        3250 Saint Matthews Rd    Orangeburg    SC 29118-8299    45 45075\n6           471 University Pkwy         Aiken    SC      29801    45 45003\n7         465 James Brandt Blvd     Allendale    SC 29810-0617    45 45005\n8             300 College St NE    Orangeburg    SC 29117-0001    45 45075\n9              481 Porter Drive       Denmark    SC      29042    45 45009\n10        225 Richland Ave East         Aiken    SC      29801    45 45003\n              NMCNTY LOCALE      LAT       LON  CBSA\n1       Aiken County     41 33.53383 -81.84167 12260\n2  Orangeburg County     32 33.49844 -80.85432 36700\n3     Bamberg County     41 33.31336 -81.12363     N\n4       Aiken County     21 33.49759 -81.95789 12260\n5  Orangeburg County     41 33.54485 -80.82927 36700\n6       Aiken County     21 33.57270 -81.76761 12260\n7   Allendale County     41 33.01431 -81.30184     N\n8  Orangeburg County     32 33.49797 -80.84872 36700\n9     Bamberg County     32 33.30720 -81.12786     N\n10      Aiken County     21 33.55954 -81.71728 12260\n                           NMCBSA CBSATYPE CSA                            NMCSA\n1  Augusta-Richmond County, GA-SC        1   N                                N\n2                  Orangeburg, SC        2 192 Columbia-Orangeburg-Newberry, SC\n3                               N        0   N                                N\n4  Augusta-Richmond County, GA-SC        1   N                                N\n5                  Orangeburg, SC        2 192 Columbia-Orangeburg-Newberry, SC\n6  Augusta-Richmond County, GA-SC        1   N                                N\n7                               N        0   N                                N\n8                  Orangeburg, SC        2 192 Columbia-Orangeburg-Newberry, SC\n9                               N        0   N                                N\n10 Augusta-Richmond County, GA-SC        1   N                                N\n   NECTA NMNECTA   CD  SLDL  SLDU SCHOOLYEAR                 geometry\n1      N       N 4502 45084 45025  2019-2020 POINT (1743560 619744.3)\n2      N       N 4506 45095 45039  2019-2020 POINT (2044404 605856.3)\n3      N       N 4506 45090 45040  2019-2020 POINT (1962235 538509.9)\n4      N       N 4502 45083 45024  2019-2020 POINT (1708029 606866.3)\n5      N       N 4506 45095 45040  2019-2020 POINT (2052011 622751.3)\n6      N       N 4502 45081 45025  2019-2020 POINT (1766228 633710.3)\n7      N       N 4506 45091 45045  2019-2020 POINT (1907482 429827.9)\n8      N       N 4506 45095 45039  2019-2020 POINT (2046110 605685.6)\n9      N       N 4506 45090 45040  2019-2020 POINT (1960939 536271.9)\n10     N       N 4502 45081 45026  2019-2020 POINT (1781522 628812.8)\n\n\n\n\n\n# Post-Secondary Location data 2019-2020\nlscog_college_loc = arc_read(\n    url=\"https://nces.ed.gov/opengis/rest/services/Postsecondary_School_Locations/EDGE_GEOCODE_POSTSECONDARYSCH_1920/MapServer/0\",\n    where=f\"STATE = '{state_abb}' AND CNTY IN ('{\"', '\".join([f\"{fip}\" for fip in fips_codes])}')\",\n    outFields='*',\n    outSR=project_crs\n)\n\nlscog_college_loc = lscog_college_loc.to_crs(project_crs)\n\nlscog_college_loc\n\n    OBJECTID  UNITID  ... SCHOOLYEAR                        geometry\n0       3411  217615  ...  2019-2020  POINT (1743561.221 619741.983)\n1       3424  217873  ...  2019-2020  POINT (2044404.666 605853.958)\n2       3431  217989  ...  2019-2020  POINT (1962236.326 538507.569)\n3       3439  218159  ...  2019-2020  POINT (1708030.354 606863.953)\n4       3448  218487  ...  2019-2020   POINT (2052011.899 622748.89)\n5       3451  218645  ...  2019-2020  POINT (1766228.593 633707.888)\n6       3455  218681  ...  2019-2020  POINT (1907483.079 429825.628)\n7       3459  218733  ...  2019-2020  POINT (2046110.928 605683.233)\n8       3468  218919  ...  2019-2020   POINT (1960940.241 536269.53)\n9       5829  457998  ...  2019-2020  POINT (1781523.402 628810.398)\n10      6683  488022  ...  2019-2020  POINT (2043606.983 603651.758)\n\n[11 rows x 25 columns]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#household-weighted-interpolation",
    "href": "posts/socioeconomic-demo/index.html#household-weighted-interpolation",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "4.1 Household-weighted interpolation",
    "text": "4.1 Household-weighted interpolation\nThe interpolation process transfers ACS block group data to individual census blocks using household counts as weights. This method ensures that socioeconomic characteristics are distributed proportionally based on residential density rather than simple geometric overlay. The tidycensus package provides robust interpolation functionality that preserves the extensive nature of count variables while maintaining spatial relationships.\n\nRPython\n\n\n\n# Interpolate ACS data to Decennial Census blocks\nlscog_acs_cb &lt;- tidycensus::interpolate_pw(\n  from = lscog_acs,\n  to = lscog_dec,\n  to_id = \"GEOID\",\n  extensive = TRUE,\n  weights = lscog_dec,\n  crs = project_crs,\n  weight_column = \"HH\"\n)\n\nhead(lscog_acs_cb, 10)\n\nSimple feature collection with 10 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1960882 ymin: 510808.3 xmax: 2115713 ymax: 708246.8\nProjected CRS: NAD83(HARN) / South Carolina (ft)\n# A tibble: 10 Ã— 6\n   GEOID                        geometry INC_TOTAL INC_14999 INC_49999 INC_50000\n   &lt;chr&gt;           &lt;MULTIPOLYGON [foot]&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 4501795040â€¦ (((2084301 622308.5, 208â€¦      0        0         0         0    \n 2 4501795040â€¦ (((2112519 626782.2, 211â€¦      0        0         0         0    \n 3 4501795020â€¦ (((2067775 662339.5, 206â€¦     20.6      4.27      7.56      8.72 \n 4 4501795040â€¦ (((2087947 684345.6, 208â€¦      0        0         0         0    \n 5 4507501050â€¦ (((2089073 552687.4, 208â€¦      5.78     1.94      0.924     2.92 \n 6 4507501170â€¦ (((2046694 542273.9, 204â€¦      2.48     0.393     1.30      0.780\n 7 4507501170â€¦ (((2056704 510850.5, 205â€¦      0        0         0         0    \n 8 4507501180â€¦ (((1960896 587381.7, 196â€¦      3.19     0.694     1.42      1.08 \n 9 4507501200â€¦ (((2000969 657869.3, 200â€¦      0        0         0         0    \n10 4501795010â€¦ (((2016178 708106.6, 201â€¦      0        0         0         0    \n\n\n\n\n\n\nCode\n# Create function for population-weighted interpolation\ndef interpolate_pw(from_gdf, to_gdf, to_id, extensive=True, weights=None, weight_column=None, crs=None):\n    \"\"\"\n    Population-weighted interpolation between geometries.\n    \n    Uses point-based spatial interpolation with weight points to transfer data\n    between incongruent geometries, following Esri's data apportionment algorithm.\n    \n    Parameters:\n    -----------\n    from_gdf : GeoDataFrame\n        Source geometries with data to interpolate\n    to_gdf : GeoDataFrame  \n        Target geometries to interpolate to\n    to_id : str\n        Column name for unique identifier in target geometries\n    extensive : bool, default True\n        If True, variables are extensive (sum). If False, intensive (average)\n    weights : GeoDataFrame\n        Weight geometries (will be converted to points). In R this is typically Census blocks.\n    weight_column : str, optional\n        Column name in weights for population weights (e.g., 'HH', 'POP')\n    crs : str or CRS object, optional\n        Coordinate reference system to project all datasets to\n        \n    Returns:\n    --------\n    GeoDataFrame\n        Target geometries with interpolated values\n    \"\"\"\n    # Set CRS if provided\n    if crs:\n        from_gdf = from_gdf.to_crs(crs)\n        to_gdf = to_gdf.to_crs(crs)\n        if weights is not None:\n            weights = weights.to_crs(crs)\n    \n    # Use weights as provided, or fall back to to_gdf\n    if weights is None:\n        weights = to_gdf.copy()\n    \n    # Convert weight polygons to points (point on surface)\n    if weights.geometry.geom_type.iloc[0] != 'Point':\n        weight_points = weights.copy()\n        weight_points.geometry = weight_points.geometry.representative_point()\n    else:\n        weight_points = weights.copy()\n    \n    # Set up weight values\n    if weight_column and weight_column in weight_points.columns:\n        weight_points['weight_val'] = weight_points[weight_column].fillna(0)\n    else:\n        weight_points['weight_val'] = 1\n    \n    # Step 1: Intersect from and to geometries\n    from_to_intersect = gpd.overlay(from_gdf, to_gdf, how='intersection')\n    \n    # Step 2: Spatial join weight points with intersections\n    intersect_weights = gpd.sjoin(from_to_intersect, weight_points, how='left', predicate='contains')\n    \n    # Step 3: Calculate weights for each from-to intersection\n    intersect_weights['point_weight'] = intersect_weights['weight_val'].fillna(0)\n    \n    # Group by from-to intersection and sum weights\n    intersection_totals = intersect_weights.groupby([from_to_intersect.index, to_id]).agg({\n        'point_weight': 'sum'\n    }).reset_index()\n    \n    # Step 4: Calculate proportion of each source going to each target\n    intersection_totals['from_idx'] = intersection_totals['level_0']\n    source_totals = intersection_totals.groupby('from_idx')['point_weight'].sum()\n    intersection_totals['weight_prop'] = intersection_totals.apply(\n        lambda row: row['point_weight'] / source_totals[row['from_idx']] if source_totals[row['from_idx']] &gt; 0 else 0,\n        axis=1\n    )\n    \n    # Step 5: Interpolate numeric columns\n    numeric_cols = from_gdf.select_dtypes(include=['number']).columns\n    result = to_gdf[[to_id, 'geometry']].copy()\n    \n    for col in numeric_cols:\n        if col in from_gdf.columns:\n            # Map source values to intersections\n            intersection_totals['source_val'] = intersection_totals['from_idx'].map(\n                from_gdf[col].to_dict()\n            )\n            \n            if extensive:\n                # For extensive variables, multiply by weight proportion\n                intersection_totals['contrib'] = intersection_totals['source_val'] * intersection_totals['weight_prop']\n            else:\n                # For intensive variables, weight by proportion\n                intersection_totals['contrib'] = intersection_totals['source_val'] * intersection_totals['weight_prop']\n            \n            # Sum contributions by target zone\n            target_vals = intersection_totals.groupby(to_id)['contrib'].sum()\n            \n            # For intensive variables, divide by total weight proportion\n            if not extensive:\n                target_weights = intersection_totals.groupby(to_id)['weight_prop'].sum()\n                target_vals = target_vals / target_weights.replace(0, 1)\n            \n            result[col] = result[to_id].map(target_vals).fillna(0)\n    \n    return result\n\n\n\n# Interpolate ACS data to Decennial Census blocks\nlscog_acs_cb = interpolate_pw(\n    from_gdf=lscog_acs,\n    to_gdf=lscog_dec,\n    to_id='GEOID',\n    extensive=True,\n    weight_column='HH',\n    crs=project_crs\n)\n\nlscog_acs_cb.head(10)\n\n             GEOID  ... INC_50000\n0  450179504004051  ...       0.0\n1  450179504003011  ...       0.0\n2  450179502011045  ...       0.0\n3  450179504001020  ...       0.0\n4  450750105003029  ...       0.0\n5  450750117021009  ...       0.0\n6  450750117011051  ...       0.0\n7  450750118021087  ...       0.0\n8  450750120003020  ...       0.0\n9  450179501003046  ...       0.0\n\n[10 rows x 6 columns]\n\n\n\n\n\nThe comparative visualization reveals the increased spatial resolution achieved through interpolation. Block-level data provides more granular detail for transportation modeling applications, enabling better representation of local variations in income distribution across the study area.\n\nRPython\n\n\n\n# Compare before and after interpolation\nmapview::mapview(lscog_acs_cb, zcol = \"INC_49999\", color = NA) |\n  mapview::mapview(lscog_acs, zcol = \"INC_49999\", color = NA)\n\n\n\n\n# Compare before and after interpolation\nlscog_acs_cb.explore(column=\"INC_49999\", color=\"blue\", legend=True, tiles=\"CartoDB positron\") |\\\n    lscog_acs.explore(column=\"INC_49999\", color=\"red\", legend=True, tiles=\"CartoDB positron\")"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#combine-population-and-households",
    "href": "posts/socioeconomic-demo/index.html#combine-population-and-households",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "4.2 Combine population and households",
    "text": "4.2 Combine population and households\nThe integration step merges the interpolated ACS socioeconomic data with the Decennial Census population and household counts. This join operation creates a unified dataset containing both demographic totals and detailed characteristics at the census block level. The left join ensures that all census blocks retain their geographic boundaries while incorporating available socioeconomic attributes.\n\nRPython\n\n\n\n## Combine ACS Data to Decennial data\nlscog_pop_hh &lt;- lscog_dec |&gt;\n  dplyr::left_join(\n    sf::st_drop_geometry(lscog_acs_cb),\n    by = dplyr::join_by(GEOID)\n  )\n\nstr(lscog_pop_hh)\n\nsf [13,961 Ã— 15] (S3: sf/tbl_df/tbl/data.frame)\n $ GEOID    : chr [1:13961] \"450179504004051\" \"450179504003011\" \"450179502011045\" \"450179504001020\" ...\n $ TOTPOP   : num [1:13961] 0 0 54 0 13 10 0 6 0 18 ...\n $ GQPOP    : num [1:13961] 0 0 4 0 0 0 0 0 0 0 ...\n $ HHPOP    : num [1:13961] 0 0 50 0 13 10 0 6 0 18 ...\n $ HH       : num [1:13961] 0 0 16 0 4 3 0 4 0 0 ...\n $ HH_1     : num [1:13961] 0 0 3 0 0 3 0 0 0 0 ...\n $ HH_2     : num [1:13961] 0 0 1 0 3 0 0 1 0 0 ...\n $ HH_3     : num [1:13961] 0 0 3 0 0 0 0 2 0 0 ...\n $ HH_4     : num [1:13961] 0 0 9 0 1 0 0 1 0 0 ...\n $ DU       : num [1:13961] 0 0 18 0 4 8 0 4 0 1 ...\n $ geometry :sfc_MULTIPOLYGON of length 13961; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:13, 1:2] 2084301 2084461 2084474 2084523 2084529 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n $ INC_TOTAL: num [1:13961] 0 0 20.56 0 5.78 ...\n $ INC_14999: num [1:13961] 0 0 4.27 0 1.94 ...\n $ INC_49999: num [1:13961] 0 0 7.562 0 0.924 ...\n $ INC_50000: num [1:13961] 0 0 8.72 0 2.92 ...\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:14] \"GEOID\" \"TOTPOP\" \"GQPOP\" \"HHPOP\" ...\n\n\n\n\n\n## Combine ACS Data to Decennial data\nlscog_pop_hh = lscog_dec.merge(\n    lscog_acs_cb.drop(columns=['geometry']),\n    on='GEOID',\n    how='left'\n)\n\nlscog_pop_hh.info()\n\n\n\n\nIncome category adjustments reconcile the interpolated ACS estimates with actual household counts from the Decennial Census. The proportional allocation method redistributes income categories based on the ratio of interpolated totals to observed household counts, maintaining consistency between data sources. The three-tier income classification (under $15,000, $15,000-$49,999, and $50,000 and above) provides sufficient granularity for travel demand modeling while ensuring statistical reliability.\n\nRPython\n\n\n\n## Combine adjusted HH income level to Decennial census instead of ACS\nlscog_pop_hh &lt;- lscog_pop_hh |&gt;\n  dplyr::mutate(\n    INC_49999 = tidyr::replace_na(round(INC_49999 / INC_TOTAL * HH, 0), 0),\n    INC_50000 = tidyr::replace_na(round(INC_50000 / INC_TOTAL * HH, 0), 0),\n    INC_14999 = HH - (INC_49999 + INC_50000)\n  ) |&gt;\n  dplyr::select(-INC_TOTAL)\n\nstr(lscog_pop_hh)\n\nsf [13,961 Ã— 14] (S3: sf/tbl_df/tbl/data.frame)\n $ GEOID    : chr [1:13961] \"450179504004051\" \"450179504003011\" \"450179502011045\" \"450179504001020\" ...\n $ TOTPOP   : num [1:13961] 0 0 54 0 13 10 0 6 0 18 ...\n $ GQPOP    : num [1:13961] 0 0 4 0 0 0 0 0 0 0 ...\n $ HHPOP    : num [1:13961] 0 0 50 0 13 10 0 6 0 18 ...\n $ HH       : num [1:13961] 0 0 16 0 4 3 0 4 0 0 ...\n $ HH_1     : num [1:13961] 0 0 3 0 0 3 0 0 0 0 ...\n $ HH_2     : num [1:13961] 0 0 1 0 3 0 0 1 0 0 ...\n $ HH_3     : num [1:13961] 0 0 3 0 0 0 0 2 0 0 ...\n $ HH_4     : num [1:13961] 0 0 9 0 1 0 0 1 0 0 ...\n $ DU       : num [1:13961] 0 0 18 0 4 8 0 4 0 1 ...\n $ geometry :sfc_MULTIPOLYGON of length 13961; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:13, 1:2] 2084301 2084461 2084474 2084523 2084529 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n $ INC_14999: num [1:13961] 0 0 3 0 1 0 0 1 0 0 ...\n $ INC_49999: num [1:13961] 0 0 6 0 1 2 0 2 0 0 ...\n $ INC_50000: num [1:13961] 0 0 7 0 2 1 0 1 0 0 ...\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:13] \"GEOID\" \"TOTPOP\" \"GQPOP\" \"HHPOP\" ...\n\n\n\n\n\n## Combine adjusted HH income level to Decennial census instead of ACS\nlscog_pop_hh[\"INC_49999\"] = ((lscog_pop_hh[\"INC_49999\"] / lscog_pop_hh[\"INC_TOTAL\"]) * lscog_pop_hh[\"HH\"]).round().fillna(0)\nlscog_pop_hh[\"INC_50000\"] = ((lscog_pop_hh[\"INC_50000\"] / lscog_pop_hh[\"INC_TOTAL\"]) * lscog_pop_hh[\"HH\"]).round().fillna(0)\nlscog_pop_hh[\"INC_14999\"] = lscog_pop_hh[\"HH\"] - (lscog_pop_hh[\"INC_49999\"] + lscog_pop_hh[\"INC_50000\"])\n\nlscog_pop_hh = lscog_pop_hh.drop(columns=\"INC_TOTAL\")\nlscog_pop_hh.info()"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#employment-data",
    "href": "posts/socioeconomic-demo/index.html#employment-data",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "4.3 Employment data",
    "text": "4.3 Employment data\nThe employment integration incorporates LEHD (Longitudinal Employer-Household Dynamics) workplace area characteristics into the combined dataset. This addition provides employment counts by census block, enabling the development of trip attraction models and work-based travel pattern analysis. The merge operation maintains the geographic integrity of census blocks while adding employment variables essential for comprehensive transportation planning.\n\nRPython\n\n\n\n# Join LEHD Data to the Decennial data\nlscog_pop_hh_emp &lt;- lscog_pop_hh |&gt;\n  dplyr::left_join(lscog_emp, by = dplyr::join_by(GEOID))\n\nstr(lscog_pop_hh_emp)\n\nsf [13,961 Ã— 25] (S3: sf/tbl_df/tbl/data.frame)\n $ GEOID     : chr [1:13961] \"450179504004051\" \"450179504003011\" \"450179502011045\" \"450179504001020\" ...\n $ TOTPOP    : num [1:13961] 0 0 54 0 13 10 0 6 0 18 ...\n $ GQPOP     : num [1:13961] 0 0 4 0 0 0 0 0 0 0 ...\n $ HHPOP     : num [1:13961] 0 0 50 0 13 10 0 6 0 18 ...\n $ HH        : num [1:13961] 0 0 16 0 4 3 0 4 0 0 ...\n $ HH_1      : num [1:13961] 0 0 3 0 0 3 0 0 0 0 ...\n $ HH_2      : num [1:13961] 0 0 1 0 3 0 0 1 0 0 ...\n $ HH_3      : num [1:13961] 0 0 3 0 0 0 0 2 0 0 ...\n $ HH_4      : num [1:13961] 0 0 9 0 1 0 0 1 0 0 ...\n $ DU        : num [1:13961] 0 0 18 0 4 8 0 4 0 1 ...\n $ geometry  :sfc_MULTIPOLYGON of length 13961; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:13, 1:2] 2084301 2084461 2084474 2084523 2084529 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n $ INC_14999 : num [1:13961] 0 0 3 0 1 0 0 1 0 0 ...\n $ INC_49999 : num [1:13961] 0 0 6 0 1 2 0 2 0 0 ...\n $ INC_50000 : num [1:13961] 0 0 7 0 2 1 0 1 0 0 ...\n $ TOTAL_EMP : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ AGR_FOR_FI: num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ MINING    : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ CONSTRUCTI: num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ MANUFACTUR: num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ TRANSP_COM: num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ WHOLESALE : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ RETAIL    : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ FIRE      : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ SERVICES  : num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n $ PUBLIC_ADM: num [1:13961] NA NA NA NA NA NA NA NA NA NA ...\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:24] \"GEOID\" \"TOTPOP\" \"GQPOP\" \"HHPOP\" ...\n\n\n\n\n\n# Join LEHD Data to the Decennial data\nlscog_pop_hh_emp = lscog_pop_hh.merge(\n    lscog_emp,\n    on='GEOID',\n    how='left'\n)\n\nlscog_pop_hh_emp.info()"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#taz-data",
    "href": "posts/socioeconomic-demo/index.html#taz-data",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.1 TAZ data",
    "text": "5.1 TAZ data\nThe Traffic Analysis Zone (TAZ) boundary export provides the fundamental geographic framework for the regional travel demand model. The blank TAZ file serves as a template for subsequent socioeconomic data allocation, containing only zone identification fields and geometric boundaries without attribute data.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_taz |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_taz_blank.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_taz.to_csv(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_taz_blank.csv\",\n    index=False\n)\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_taz |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_taz_blank\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_taz.to_file(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n    layer='lscog_taz_blank',\n    driver='FileGDB'\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#census-blocks-to-taz-conversion",
    "href": "posts/socioeconomic-demo/index.html#census-blocks-to-taz-conversion",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.2 Census blocks to TAZ conversion",
    "text": "5.2 Census blocks to TAZ conversion\nThe block-to-TAZ conversion table establishes the critical linkage between fine-scale Census geography and the modeling zone system. This crosswalk file enables the aggregation of block-level socioeconomic data to TAZ boundaries while maintaining traceability to source geographies.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_cb |&gt;\n  sf::st_join(lscog_taz) |&gt;\n  dplyr::select(GEOID20, ID, TAZ_ID) |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_block_taz.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_cb.merge(lscog_taz[['ID', 'TAZ_ID']], left_on='GEOID20', right_on='ID')[['GEOID20', 'ID', 'TAZ_ID']].to_csv(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_block_taz.csv\",\n    index=False\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#decennial-census-data-at-census-block-level",
    "href": "posts/socioeconomic-demo/index.html#decennial-census-data-at-census-block-level",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.3 Decennial census data at census block level",
    "text": "5.3 Decennial census data at census block level\nThe decennial census block export captures the foundational demographic counts used throughout the modeling process. This dataset provides the most reliable population and household totals at the finest geographic resolution, serving as the base for all subsequent data integration and validation steps.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_dec |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_dec_block.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_dec.to_csv(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_dec_block.csv\",\n    index=False\n)\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_dec |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_dec_block\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_dec.to_file(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n    layer='lscog_dec_block',\n    driver='FileGDB'\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#acs-estimates-at-census-block-level",
    "href": "posts/socioeconomic-demo/index.html#acs-estimates-at-census-block-level",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.4 ACS estimates at census block level",
    "text": "5.4 ACS estimates at census block level\nThe interpolated ACS data export delivers income distribution estimates at the census block level, providing the socioeconomic stratification necessary for trip generation modeling. This processed dataset represents the final product of the household-weighted interpolation methodology, ready for direct integration into the travel demand model framework.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_acs_cb |&gt;\n  dplyr::select(GEOID, INC_14999, INC_49999, INC_50000) |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_acs_block.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_acs_cb[['GEOID', 'INC_14999', 'INC_49999', 'INC_50000']].to_csv(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_acs_block.csv\",\n    index=False\n)\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_acs_cb |&gt;\n  dplyr::select(GEOID, INC_14999, INC_49999, INC_50000) |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_acs_block\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_acs_cb[['GEOID', 'INC_14999', 'INC_49999', 'INC_50000']].to_file(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n    layer='lscog_acs_block',\n    driver='FileGDB'\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#lehd-data-at-census-block-level",
    "href": "posts/socioeconomic-demo/index.html#lehd-data-at-census-block-level",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.5 LEHD data at census block level",
    "text": "5.5 LEHD data at census block level\nThe employment data export provides comprehensive workplace characteristics by industry sector at the census block level. This dataset captures the spatial distribution of employment opportunities across the study region, supporting both trip attraction modeling and economic impact analysis.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_pop_hh_emp |&gt;\n  dplyr::select(GEOID, TOTAL_EMP:PUBLIC_ADM) |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_emp_block.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_pop_hh_emp[['GEOID', 'TOTAL_EMP', 'AGR_FOR_FI', 'MINING', 'CONSTRUCTI',\n                   'MANUFACTUR', 'TRANSP_COM', 'WHOLESALE', 'RETAIL', 'FIRE',\n                   'SERVICES', 'PUBLIC_ADM']].to_csv(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_emp_block.csv\",\n    index=False\n)\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_pop_hh_emp |&gt;\n  dplyr::select(GEOID, TOTAL_EMP:PUBLIC_ADM) |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_emp_block\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_pop_hh_emp[['GEOID', 'TOTAL_EMP', 'AGR_FOR_FI', 'MINING', 'CONSTRUCTI',\n                   'MANUFACTUR', 'TRANSP_COM', 'WHOLESALE', 'RETAIL', 'FIRE',\n                   'SERVICES', 'PUBLIC_ADM']].to_file(\n        Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n        layer='lscog_emp_block',\n        driver='FileGDB'\n    )"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#public-schools-to-taz",
    "href": "posts/socioeconomic-demo/index.html#public-schools-to-taz",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.6 Public schools to TAZ",
    "text": "5.6 Public schools to TAZ\nThe public school location export integrates educational facility data with the TAZ system, providing essential inputs for school-related trip modeling. Student and teacher counts by facility support the development of specialized trip generation rates for educational purposes.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_pub_sch_enroll |&gt;\n  sf::st_join(lscog_taz |&gt; dplyr::select(ID, TAZ_ID)) |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_pubsch_loc.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_pub_sch_enroll.sjoin(\n    lscog_taz[['ID', 'TAZ_ID']],\n    how='left'\n)[['INSTITUTION_ID', 'NAME', 'STATE', 'STUDENT_COUNT_PUB', 'TEACHER_COUNT_PUB', 'geometry']] \\\n    .to_csv(\n        Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_pubsch_loc.csv\",\n        index=False\n    )\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_pub_sch_enroll |&gt;\n  sf::st_join(lscog_taz |&gt; dplyr::select(ID, TAZ_ID)) |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_pubsch_loc\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_pub_sch_enroll.sjoin(\n    lscog_taz[['ID', 'TAZ_ID']],\n    how='left'\n).to_file(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n    layer='lscog_pubsch_loc',\n    driver='FileGDB'\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#private-schools-to-taz",
    "href": "posts/socioeconomic-demo/index.html#private-schools-to-taz",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "5.7 Private schools to TAZ",
    "text": "5.7 Private schools to TAZ\nThe private school dataset complements the public education data by capturing enrollment patterns in private educational institutions. This comprehensive coverage of educational facilities ensures that all school-related travel demand is properly represented in the regional model.\nExport as CSV flat file\n\nRPython\n\n\n\n# Export as CSV\nlscog_pvt_sch_enroll |&gt;\n  sf::st_join(lscog_taz |&gt; dplyr::select(ID, TAZ_ID)) |&gt;\n  sf::st_drop_geometry() |&gt;\n  readr::write_csv(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_raw/lscog_pvtsch_loc.csv\"\n    ),\n    append = FALSE\n  )\n\n\n\n\n# Export as CSV\nlscog_pvt_sch_enroll.sjoin(\n    lscog_taz[['ID', 'TAZ_ID']],\n    how='left'\n)[['INSTITUTION_ID', 'NAME', 'STATE', 'STUDENT_COUNT_PVT', 'TEACHER_COUNT_PVT', 'geometry']] \\\n    .to_csv(\n        Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_raw\" / \"lscog_pvtsch_loc.csv\",\n        index=False\n    )\n\n\n\n\nExport as Geodatabase layer\n\nRPython\n\n\n\n# Export as GDB\nlscog_pvt_sch_enroll |&gt;\n  sf::st_join(lscog_taz |&gt; dplyr::select(ID, TAZ_ID)) |&gt;\n  sf::write_sf(\n    file.path(\n      root,\n      \"Task 1 TDM Development/Base Year/_gis/LSCOG_2020Base_SE.gdb\"\n    ),\n    layer = \"lscog_pvtsch_loc\",\n    append = FALSE\n  )\n\n\n\n\n# Export as GDB\nlscog_pvt_sch_enroll.sjoin(\n    lscog_taz[['ID', 'TAZ_ID']],\n    how='left'\n).to_file(\n    Path(root) / \"Task 1 TDM Development\" / \"Base Year\" / \"_gis\" / \"LSCOG_2020Base_SE.gdb\",\n    layer='lscog_pvtsch_loc',\n    driver='FileGDB'\n)"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#population-households-and-employment",
    "href": "posts/socioeconomic-demo/index.html#population-households-and-employment",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "6.1 Population, households, and employment",
    "text": "6.1 Population, households, and employment\nThe spatial join operation aggregates all demographic, housing, and employment variables from census blocks to their corresponding TAZs using centroid-based assignment. This process ensures that each blockâ€™s socioeconomic characteristics are properly allocated to the appropriate modeling zone while maintaining data integrity through comprehensive summation of all relevant variables.\n\nRPython\n\n\n\n# Aggregate population, households, and employment to TAZ\nlscog_taz_pop &lt;- lscog_taz |&gt;\n  sf::st_join(\n    lscog_pop_hh_emp |&gt; sf::st_centroid(of_largest_polygon = TRUE)\n  ) |&gt;\n  dplyr::group_by(\n    ID,\n    Area,\n    TAZ_ID,\n    COUNTY,\n    AREA_TYPE,\n    COUNTYID,\n    .drop = FALSE\n  ) |&gt;\n  dplyr::summarize(\n    .groups = \"drop\",\n    # Population and Household Size\n    TOTPOP = sum(TOTPOP, na.rm = TRUE),\n    GQPOP = sum(GQPOP, na.rm = TRUE),\n    HHPOP = sum(HHPOP, na.rm = TRUE),\n    HH = sum(HH, na.rm = TRUE),\n    HH_1 = sum(HH_1, na.rm = TRUE),\n    HH_2 = sum(HH_2, na.rm = TRUE),\n    HH_3 = sum(HH_3, na.rm = TRUE),\n    HH_4 = sum(HH_4, na.rm = TRUE),\n    DU = sum(DU, na.rm = TRUE),\n    # Household Income\n    INC_14999 = sum(INC_14999, na.rm = TRUE),\n    INC_49999 = sum(INC_49999, na.rm = TRUE),\n    INC_50000 = sum(INC_50000, na.rm = TRUE),\n    # Employment\n    TOTAL_EMP = sum(TOTAL_EMP, na.rm = TRUE),\n    AGR_FOR_FI = sum(AGR_FOR_FI, na.rm = TRUE),\n    MINING = sum(MINING, na.rm = TRUE),\n    CONSTRUCTI = sum(CONSTRUCTI, na.rm = TRUE),\n    MANUFACTUR = sum(MANUFACTUR, na.rm = TRUE),\n    TRANSP_COM = sum(TRANSP_COM, na.rm = TRUE),\n    WHOLESALE = sum(WHOLESALE, na.rm = TRUE),\n    RETAIL = sum(RETAIL, na.rm = TRUE),\n    FIRE = sum(FIRE, na.rm = TRUE),\n    SERVICES = sum(SERVICES, na.rm = TRUE),\n    PUBLIC_ADM = sum(PUBLIC_ADM, na.rm = TRUE)\n  )\n\nWarning: st_centroid assumes attributes are constant over geometries\n\nstr(lscog_taz_pop)\n\nsf [585 Ã— 30] (S3: sf/tbl_df/tbl/data.frame)\n $ ID        : int [1:585] 3010700 3010701 3010702 3010703 3010704 3010705 3010706 3010707 3010708 3010709 ...\n $ Area      : num [1:585] 0.846 1.098 0.395 0.338 0.381 ...\n $ TAZ_ID    : int [1:585] 3010700 3010701 3010702 3010703 3010704 3010705 3010706 3010707 3010708 3010709 ...\n $ COUNTY    : chr [1:585] \"Aiken SC\" \"Aiken SC\" \"Aiken SC\" \"Aiken SC\" ...\n $ AREA_TYPE : chr [1:585] \"SUBURBAN\" \"URBAN\" \"URBAN\" \"URBAN\" ...\n $ COUNTYID  : int [1:585] 45003 45003 45003 45003 45003 45003 45003 45003 45003 45003 ...\n $ TOTPOP    : num [1:585] 66 1299 657 593 462 ...\n $ GQPOP     : num [1:585] 0 0 0 1 0 0 0 0 0 0 ...\n $ HHPOP     : num [1:585] 66 1299 657 592 462 ...\n $ HH        : num [1:585] 20 482 268 237 261 189 62 194 67 71 ...\n $ HH_1      : num [1:585] 2 84 46 67 152 64 5 50 19 30 ...\n $ HH_2      : num [1:585] 0 211 130 82 65 61 16 92 22 25 ...\n $ HH_3      : num [1:585] 5 97 49 21 18 29 17 18 16 14 ...\n $ HH_4      : num [1:585] 13 90 43 67 26 35 24 34 10 2 ...\n $ DU        : num [1:585] 22 512 274 257 279 193 71 196 79 74 ...\n $ INC_14999 : num [1:585] 0 12 5 7 49 3 1 0 0 0 ...\n $ INC_49999 : num [1:585] 4 85 88 86 48 69 23 99 35 36 ...\n $ INC_50000 : num [1:585] 16 385 175 144 164 117 38 95 32 35 ...\n $ TOTAL_EMP : num [1:585] 21 13 58 13 43 54 101 17 0 0 ...\n $ AGR_FOR_FI: num [1:585] 0 0 0 0 0 0 0 0 0 0 ...\n $ MINING    : num [1:585] 0 0 0 0 0 0 0 0 0 0 ...\n $ CONSTRUCTI: num [1:585] 0 3 2 1 0 0 0 3 0 0 ...\n $ MANUFACTUR: num [1:585] 0 0 0 0 0 0 0 0 0 0 ...\n $ TRANSP_COM: num [1:585] 0 0 1 0 15 0 0 0 0 0 ...\n $ WHOLESALE : num [1:585] 0 0 0 0 0 0 0 0 0 0 ...\n $ RETAIL    : num [1:585] 19 0 0 0 15 8 9 0 0 0 ...\n $ FIRE      : num [1:585] 0 5 0 0 13 5 17 2 0 0 ...\n $ SERVICES  : num [1:585] 2 5 55 12 0 41 75 12 0 0 ...\n $ PUBLIC_ADM: num [1:585] 0 0 0 0 0 0 0 0 0 0 ...\n $ SHAPE     :sfc_MULTIPOLYGON of length 585; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:100, 1:2] 1699181 1699124 1699097 1699072 1699041 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"SHAPE\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:29] \"ID\" \"Area\" \"TAZ_ID\" \"COUNTY\" ...\n\n\n\n\n\n# Aggregate population, households, and employment to TAZ\nlscog_taz_pop = lscog_taz.sjoin(\n    lscog_pop_hh_emp.to_crs(project_crs),\n    how='left'\n).groupby(\n    ['ID', 'Area', 'TAZ_ID', 'COUNTY', 'AREA_TYPE', 'COUNTYID'],\n    as_index=False\n).agg({\n    'TOTPOP': 'sum',\n    'GQPOP': 'sum',\n    'HHPOP': 'sum',\n    'HH': 'sum',\n    'HH_1': 'sum',\n    'HH_2': 'sum',\n    'HH_3': 'sum',\n    'HH_4': 'sum',\n    'DU': 'sum',\n    'INC_14999': 'sum',\n    'INC_49999': 'sum',\n    'INC_50000': 'sum',\n    'TOTAL_EMP': 'sum',\n    'AGR_FOR_FI': 'sum',\n    'MINING': 'sum',\n    'CONSTRUCTI': 'sum',\n    'MANUFACTUR': 'sum',\n    'TRANSP_COM': 'sum',\n    'WHOLESALE': 'sum',\n    'RETAIL': 'sum',\n    'FIRE': 'sum',\n    'SERVICES': 'sum',\n    'PUBLIC_ADM': 'sum'\n})\n\nlscog_taz_pop.info()"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#school-and-college-enrollment",
    "href": "posts/socioeconomic-demo/index.html#school-and-college-enrollment",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "6.2 School and college enrollment",
    "text": "6.2 School and college enrollment\nThe school enrollment combination merges public and private educational institution data into a unified dataset for comprehensive coverage of student populations.\n\nRPython\n\n\n\n# Combine school enrollment data\nlscog_sch_enroll &lt;- dplyr::bind_rows(\n  lscog_pub_sch_enroll,\n  lscog_pvt_sch_enroll\n) |&gt;\n  dplyr::mutate(\n    STUDENT_COUNT = dplyr::coalesce(STUDENT_COUNT_PUB, 0) +\n      dplyr::coalesce(STUDENT_COUNT_PVT, 0),\n    TEACHER_COUNT = dplyr::coalesce(TEACHER_COUNT_PUB, 0) +\n      dplyr::coalesce(TEACHER_COUNT_PVT, 0)\n  )\n\nstr(lscog_sch_enroll)\n\nClasses 'sf' and 'data.frame':  122 obs. of  10 variables:\n $ INSTITUTION_ID   : chr  \"450108001163\" \"450075000064\" \"450075001184\" \"450075001415\" ...\n $ NAME             : chr  \"Barnwell Elementary\" \"Allendale Fairfax High\" \"Allendale Elementary\" \"Allendale-Fairfax Middle\" ...\n $ STATE            : chr  \"SC\" \"SC\" \"SC\" \"SC\" ...\n $ STUDENT_COUNT_PUB: num  462 283 245 268 381 188 162 149 353 0 ...\n $ TEACHER_COUNT_PUB: num  32 28.9 18 18 28.5 15 20 10 25 12 ...\n $ STUDENT_COUNT_PVT: num  NA NA NA NA NA NA NA NA NA NA ...\n $ TEACHER_COUNT_PVT: num  NA NA NA NA NA NA NA NA NA NA ...\n $ geometry         :sfc_POINT of length 122; first list element:  'XY' num  1891531 517379\n $ STUDENT_COUNT    : num  462 283 245 268 381 188 162 149 353 0 ...\n $ TEACHER_COUNT    : num  32 28.9 18 18 28.5 15 20 10 25 12 ...\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:9] \"INSTITUTION_ID\" \"NAME\" \"STATE\" \"STUDENT_COUNT_PUB\" ...\n\n\n\n\n\n# Combine school enrollment data\nlscog_sch_enroll = pd.concat([\n    lscog_pub_sch_enroll.assign(\n        STUDENT_COUNT=lscog_pub_sch_enroll['STUDENT_COUNT_PUB'],\n        TEACHER_COUNT=lscog_pub_sch_enroll['TEACHER_COUNT_PUB']\n    ),\n    lscog_pvt_sch_enroll.assign(\n        STUDENT_COUNT=lscog_pvt_sch_enroll['STUDENT_COUNT_PVT'],\n        TEACHER_COUNT=lscog_pvt_sch_enroll['TEACHER_COUNT_PVT']\n    )\n])\n\nlscog_sch_enroll.info()\n\n\n\n\nThe subsequent TAZ aggregation counts total student enrollment within each zone, providing essential data for modeling education-related trip patterns and supporting specialized trip generation rates for school-based travel.\n\nRPython\n\n\n\n# count the number of school enrollment within each TAZ\nlscog_taz_enroll &lt;- lscog_taz |&gt;\n  sf::st_join(lscog_sch_enroll) |&gt;\n  dplyr::group_by(\n    ID,\n    Area,\n    TAZ_ID,\n    COUNTY,\n    AREA_TYPE,\n    COUNTYID,\n    .drop = FALSE\n  ) |&gt;\n  dplyr::summarize(\n    .groups = \"drop\",\n    STUDENT_COUNT = sum(STUDENT_COUNT, na.rm = TRUE)\n  )\n\nstr(lscog_taz_enroll)\n\nsf [585 Ã— 8] (S3: sf/tbl_df/tbl/data.frame)\n $ ID           : int [1:585] 3010700 3010701 3010702 3010703 3010704 3010705 3010706 3010707 3010708 3010709 ...\n $ Area         : num [1:585] 0.846 1.098 0.395 0.338 0.381 ...\n $ TAZ_ID       : int [1:585] 3010700 3010701 3010702 3010703 3010704 3010705 3010706 3010707 3010708 3010709 ...\n $ COUNTY       : chr [1:585] \"Aiken SC\" \"Aiken SC\" \"Aiken SC\" \"Aiken SC\" ...\n $ AREA_TYPE    : chr [1:585] \"SUBURBAN\" \"URBAN\" \"URBAN\" \"URBAN\" ...\n $ COUNTYID     : int [1:585] 45003 45003 45003 45003 45003 45003 45003 45003 45003 45003 ...\n $ STUDENT_COUNT: num [1:585] 0 0 0 0 0 717 0 0 0 0 ...\n $ SHAPE        :sfc_MULTIPOLYGON of length 585; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:100, 1:2] 1699181 1699124 1699097 1699072 1699041 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"SHAPE\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:7] \"ID\" \"Area\" \"TAZ_ID\" \"COUNTY\" ...\n\n\n\n\n\n# count the number of school enrollment within each TAZ\nlscog_taz_enroll = lscog_taz.sjoin(lscog_sch_enroll, how='left') \\\n    .groupby(['ID', 'Area', 'TAZ_ID', 'COUNTY', 'AREA_TYPE', 'COUNTYID'], as_index=False) \\\n    .agg({'STUDENT_COUNT': 'sum'})"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#household-size-total",
    "href": "posts/socioeconomic-demo/index.html#household-size-total",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "8.1 Household size total",
    "text": "8.1 Household size total\nThis validation confirms that the total household count matches the sum of all household size categories for each TAZ. Any discrepancies indicate potential issues in the household size distribution that require investigation and correction before model implementation.\n\nRPython\n\n\n\n# check the sum of household by household size\nlscog_se_base |&gt;\n  dplyr::filter(HH != (HH_1 + HH_2 + HH_3 + HH_4)) |&gt;\n  nrow()\n\n[1] 0\n\n\n\n\n\n# check the sum of household by household size\nlscog_se_base[\n    lscog_se_base['HH'] != (lscog_se_base['HH_1'] + lscog_se_base['HH_2'] +\n                            lscog_se_base['HH_3'] + lscog_se_base['HH_4'])\n].shape[0]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#household-income-total",
    "href": "posts/socioeconomic-demo/index.html#household-income-total",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "8.2 Household income total",
    "text": "8.2 Household income total\nThe income category validation verifies that household totals equal the sum of all three income brackets across all zones. This check ensures the integrity of the income distribution data following the proportional allocation methodology applied during the ACS interpolation process.\n\nRPython\n\n\n\n# check the sum of household by income level\nlscog_se_base |&gt;\n  dplyr::filter(HH != (INC_14999 + INC_49999 + INC_50000)) |&gt;\n  nrow()\n\n[1] 0\n\n\n\n\n\n# check the sum of household by income level\nlsccog_se_base[\n    lscog_se_base['HH'] != (lscog_se_base['INC_14999'] + lscog_se_base['INC_49999'] +\n                            lscog_se_base['INC_50000'])\n].shape[0]"
  },
  {
    "objectID": "posts/socioeconomic-demo/index.html#employment-categories",
    "href": "posts/socioeconomic-demo/index.html#employment-categories",
    "title": "LSCOG 2050 LRTP - Base Year SE Data Development",
    "section": "8.3 Employment categories",
    "text": "8.3 Employment categories\nThe employment validation confirms that total employment equals the sum of all industry sector categories for each TAZ. This comprehensive check validates the LEHD data integration and ensures that no employment is lost or double-counted during the sectoral disaggregation process.RetryClaude can make mistakes. Please double-check responses.\n\nRPython\n\n\n\n# check the sum of employment by categories\nlscog_se_base |&gt;\n  dplyr::filter(\n    TOTAL_EMP !=\n      (AGR_FOR_FI +\n        MINING +\n        CONSTRUCTI +\n        MANUFACTUR +\n        TRANSP_COM +\n        WHOLESALE +\n        RETAIL +\n        FIRE +\n        SERVICES +\n        PUBLIC_ADM)\n  ) |&gt;\n  nrow()\n\n[1] 0\n\n\n\n\n\n# check the sum of employment by categories\nlscog_se_base[\n    lscog_se_base['TOTAL_EMP'] != (\n        lscog_se_base['AGR_FOR_FI'] +\n        lscog_se_base['MINING'] +\n        lscog_se_base['CONSTRUCTI'] +\n        lscog_se_base['MANUFACTUR'] +\n        lscog_se_base['TRANSP_COM'] +\n        lscog_se_base['WHOLESALE'] +\n        lscog_se_base['RETAIL'] +\n        lscog_se_base['FIRE'] +\n        lscog_se_base['SERVICES'] +\n        lscog_se_base['PUBLIC_ADM']\n    )\n].shape[0]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Pukar Bhandari",
    "section": "",
    "text": "I am an aspiring Associate Transportation Planner with a Masterâ€™s in City & Metropolitan Planning and a background in architecture, specializing in data-driven, multimodal strategies that advance equity, sustainability, and community well-being. I have over three years of hands-on experience in multimodal system evaluation, GIS modeling, benefit-cost and economic impact analysis for state and regional projects. I am skilled in leading interagency programs, managing complex contracts, and engaging diverse stakeholders to deliver innovative, resilient, and accessible transportation solutions grounded in inclusive, community-driven planning."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pukar Bhandari",
    "section": "",
    "text": "I am an aspiring Associate Transportation Planner with a Masterâ€™s in City & Metropolitan Planning and a background in architecture, specializing in data-driven, multimodal strategies that advance equity, sustainability, and community well-being. I have over three years of hands-on experience in multimodal system evaluation, GIS modeling, benefit-cost and economic impact analysis for state and regional projects. I am skilled in leading interagency programs, managing complex contracts, and engaging diverse stakeholders to deliver innovative, resilient, and accessible transportation solutions grounded in inclusive, community-driven planning.\n\n\n\n\n\nAssociate Transportation Planner | Metro Analytics | June 2023 - Present\nGraduate Teaching & Research Assistant | University of Utah | August 2021 - May 2023\nGIS Data Analyst | Energy & Geoscience Institute | June 2022 - August 2022\nAssociate Architect | Prabal Thapa Architects | June 2020 - July 2021\nArchitect & Planner | Urban Park Nepal Pvt. Ltd.Â | January 2019 - June 2020\n\n\n\n\n\n\nMaster of City & Metropolitan Planning | University of Utah | August 2021 - May 2023\nBachelors Degree in Architecture | Tribhuvan University | October 2013 - August 2018"
  },
  {
    "objectID": "index.html#professional-overview",
    "href": "index.html#professional-overview",
    "title": "Pukar Bhandari",
    "section": "",
    "text": "I am an aspiring Associate Transportation Planner with a Masterâ€™s in City & Metropolitan Planning and a background in architecture, specializing in data-driven, multimodal strategies that advance equity, sustainability, and community well-being. I have over three years of hands-on experience in multimodal system evaluation, GIS modeling, benefit-cost and economic impact analysis for state and regional projects. I am skilled in leading interagency programs, managing complex contracts, and engaging diverse stakeholders to deliver innovative, resilient, and accessible transportation solutions grounded in inclusive, community-driven planning."
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Pukar Bhandari",
    "section": "",
    "text": "Associate Transportation Planner | Metro Analytics | June 2023 - Present\nGraduate Teaching & Research Assistant | University of Utah | August 2021 - May 2023\nGIS Data Analyst | Energy & Geoscience Institute | June 2022 - August 2022\nAssociate Architect | Prabal Thapa Architects | June 2020 - July 2021\nArchitect & Planner | Urban Park Nepal Pvt. Ltd.Â | January 2019 - June 2020"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Pukar Bhandari",
    "section": "",
    "text": "Master of City & Metropolitan Planning | University of Utah | August 2021 - May 2023\nBachelors Degree in Architecture | Tribhuvan University | October 2013 - August 2018"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLSCOG 2050 LRTP - Base Year SE Data Development\n\n\n\nr\n\npython\n\ngis\n\ndata science\n\nspatial analysis\n\ntransportation\n\n\n\n\n\n\n\n\n\nJul 5, 2025\n\n\nPukar Bhandari\n\n\n\n\n\nNo matching items"
  }
]